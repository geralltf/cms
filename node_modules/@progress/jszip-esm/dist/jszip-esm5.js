import { Deflate, Inflate } from '@progress/pako-esm';

/**
 * Let the user use/change some implementations.
 */
var external = {
    Promise: Promise
};

var support = {
    base64: true,
    array: true,
    string: true,
    nodebuffer: false,
    nodestream: false,

    get arraybuffer() {
        return typeof ArrayBuffer !== "undefined" && typeof Uint8Array !== "undefined";
    },

    // Returns true if JSZip can read/generate Uint8Array, false otherwise.
    get uint8array() {
        return typeof Uint8Array !== "undefined";
    },

    get blob() {
        return blob();
    }
};

var blob = function() {
    var supported;

    if (typeof ArrayBuffer === "undefined") {
        supported = false;
    } else {
        var buffer = new ArrayBuffer(0);
        try {
            supported = new Blob([ buffer ], {
                type: "application/zip"
            }).size === 0;
        } catch (e) {
            supported = false;
        }
    }

    blob = function () { return supported; };
    return supported;
};

/* eslint-disable */

// private property
var _keyStr = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=";

// public method for encoding
var encode = function(input) {
    var output = [];
    var chr1, chr2, chr3, enc1, enc2, enc3, enc4;
    var i = 0, len = input.length, remainingBytes = len;

    var isArray = typeof input !== "string";
    while (i < input.length) {
        remainingBytes = len - i;

        if (!isArray) {
            chr1 = input.charCodeAt(i++);
            chr2 = i < len ? input.charCodeAt(i++) : 0;
            chr3 = i < len ? input.charCodeAt(i++) : 0;
        } else {
            chr1 = input[i++];
            chr2 = i < len ? input[i++] : 0;
            chr3 = i < len ? input[i++] : 0;
        }

        enc1 = chr1 >> 2;
        enc2 = ((chr1 & 3) << 4) | (chr2 >> 4);
        enc3 = remainingBytes > 1 ? (((chr2 & 15) << 2) | (chr3 >> 6)) : 64;
        enc4 = remainingBytes > 2 ? (chr3 & 63) : 64;

        output.push(_keyStr.charAt(enc1) + _keyStr.charAt(enc2) + _keyStr.charAt(enc3) + _keyStr.charAt(enc4));

    }

    return output.join("");
};

// public method for decoding
var decode = function(input) {
    var chr1, chr2, chr3;
    var enc1, enc2, enc3, enc4;
    var i = 0, resultIndex = 0;

    var dataUrlPrefix = "data:";

    if (input.substr(0, dataUrlPrefix.length) === dataUrlPrefix) {
        // This is a common error: people give a data url
        // (data:image/png;base64,iVBOR...) with a {base64: true} and
        // wonders why things don't work.
        // We can detect that the string input looks like a data url but we
        // *can't* be sure it is one: removing everything up to the comma would
        // be too dangerous.
        throw new Error("Invalid base64 input, it looks like a data url.");
    }

    input = input.replace(/[^A-Za-z0-9\+\/\=]/g, "");

    var totalLength = input.length * 3 / 4;
    if(input.charAt(input.length - 1) === _keyStr.charAt(64)) {
        totalLength--;
    }
    if(input.charAt(input.length - 2) === _keyStr.charAt(64)) {
        totalLength--;
    }
    if (totalLength % 1 !== 0) {
        // totalLength is not an integer, the length does not match a valid
        // base64 content. That can happen if:
        // - the input is not a base64 content
        // - the input is *almost* a base64 content, with a extra chars at the
        //   beginning or at the end
        // - the input uses a base64 letiant (base64url for example)
        throw new Error("Invalid base64 input, bad content length.");
    }
    var output;
    if (support.uint8array) {
        output = new Uint8Array(totalLength|0);
    } else {
        output = new Array(totalLength|0);
    }

    while (i < input.length) {

        enc1 = _keyStr.indexOf(input.charAt(i++));
        enc2 = _keyStr.indexOf(input.charAt(i++));
        enc3 = _keyStr.indexOf(input.charAt(i++));
        enc4 = _keyStr.indexOf(input.charAt(i++));

        chr1 = (enc1 << 2) | (enc2 >> 4);
        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);
        chr3 = ((enc3 & 3) << 6) | enc4;

        output[resultIndex++] = chr1;

        if (enc3 !== 64) {
            output[resultIndex++] = chr2;
        }
        if (enc4 !== 64) {
            output[resultIndex++] = chr3;
        }

    }

    return output;
};

/* eslint-disable */

/**
 * Convert a string that pass as a "binary string": it should represent a byte
 * array but may have > 255 char codes. Be sure to take only the first byte
 * and returns the byte array.
 * @param {String} str the string to transform.
 * @return {Array|Uint8Array} the string in a binary format.
 */
function string2binary(str) {
    var result = null;
    if (support.uint8array) {
      result = new Uint8Array(str.length);
    } else {
      result = new Array(str.length);
    }
    return stringToArrayLike(str, result);
}

/**
 * Create a new blob with the given content and the given type.
 * @param {String|ArrayBuffer} part the content to put in the blob. DO NOT use
 * an Uint8Array because the stock browser of android 4 won't accept it (it
 * will be silently converted to a string, "[object Uint8Array]").
 *
 * Use only ONE part to build the blob to avoid a memory leak in IE11 / Edge:
 * when a large amount of Array is used to create the Blob, the amount of
 * memory consumed is nearly 100 times the original data amount.
 *
 * @param {String} type the mime type of the blob.
 * @return {Blob} the created blob.
 */
var newBlob = function(part, type) {
    checkSupport("blob");

    // Blob constructor
    return new Blob([part], {
        type: type
    });
};

/**
 * The identity function.
 * @param {Object} input the input.
 * @return {Object} the same input.
 */
function identity(input) {
    return input;
}

/**
 * Fill in an array with a string.
 * @param {String} str the string to use.
 * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to fill in (will be mutated).
 * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated array.
 */
function stringToArrayLike(str, array) {
    for (var i = 0; i < str.length; ++i) {
        array[i] = str.charCodeAt(i) & 0xFF;
    }
    return array;
}

/**
 * Transform an array of int into a string, chunk by chunk.
 * See the performances notes on arrayLikeToString.
 * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.
 * @param {String} type the type of the array.
 * @param {Integer} chunk the chunk size.
 * @return {String} the resulting string.
 * @throws Error if the chunk is too big for the stack.
 */
function stringifyByChunk(array, type, chunk) {
    var result = [], k = 0, len = array.length;
    // shortcut
    if (len <= chunk) {
        return String.fromCharCode.apply(null, array);
    }
    while (k < len) {
        if (type === "array") {
            result.push(String.fromCharCode.apply(null, array.slice(k, Math.min(k + chunk, len))));
        }
        else {
            result.push(String.fromCharCode.apply(null, array.subarray(k, Math.min(k + chunk, len))));
        }
        k += chunk;
    }
    return result.join("");
}

/**
 * Call String.fromCharCode on every item in the array.
 * This is the naive implementation, which generate A LOT of intermediate string.
 * This should be used when everything else fail.
 * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.
 * @return {String} the result.
 */
function stringifyByChar(array) {
    var resultStr = "";
    for(var i = 0; i < array.length; i++) {
        resultStr += String.fromCharCode(array[i]);
    }
    return resultStr;
}

/**
 * true if the browser accepts to use String.fromCharCode on Uint8Array
 */
var fromCharCodeSupportsTypedArrays = function () {
    var supported;
    try {
        supported = support.uint8array && String.fromCharCode.apply(null, new Uint8Array(1)).length === 1;
    } catch (e) {
        supported = false;
    }

    fromCharCodeSupportsTypedArrays = function () { return supported; };
    return supported;
};

/**
 * Transform an array-like object to a string.
 * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.
 * @return {String} the result.
 */
function arrayLikeToString(array) {
    // Performances notes :
    // --------------------
    // String.fromCharCode.apply(null, array) is the fastest, see
    // see http://jsperf.com/converting-a-uint8array-to-a-string/2
    // but the stack is limited (and we can get huge arrays !).
    //
    // result += String.fromCharCode(array[i]); generate too many strings !
    //
    // This code is inspired by http://jsperf.com/arraybuffer-to-string-apply-performance/2
    // TODO : we now have workers that split the work. Do we still need that ?
    var chunk = 65536,
        type = getTypeOf(array),
        canUseApply = true;
    if (type === "uint8array") {
        canUseApply = fromCharCodeSupportsTypedArrays();
    }

    if (canUseApply) {
        while (chunk > 1) {
            try {
                return stringifyByChunk(array, type, chunk);
            } catch (e) {
                chunk = Math.floor(chunk / 2);
            }
        }
    }

    // no apply or chunk error : slow and painful algorithm
    // default browser on android 4.*
    return stringifyByChar(array);
}

var applyFromCharCode = arrayLikeToString;


/**
 * Copy the data from an array-like to an other array-like.
 * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayFrom the origin array.
 * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayTo the destination array which will be mutated.
 * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated destination array.
 */
function arrayLikeToArrayLike(arrayFrom, arrayTo) {
    for (var i = 0; i < arrayFrom.length; i++) {
        arrayTo[i] = arrayFrom[i];
    }
    return arrayTo;
}

// a matrix containing functions to transform everything into everything.
var transform = {
    // string to ?
    "string": {
        "string": identity,
        "array": function(input) {
            return stringToArrayLike(input, new Array(input.length));
        },
        "arraybuffer": function(input) {
            return transform["string"]["uint8array"](input).buffer;
        },
        "uint8array": function(input) {
            return stringToArrayLike(input, new Uint8Array(input.length));
        }
    },

    // array to ?
    "array": {
        "string": arrayLikeToString,
        "array": identity,
        "arraybuffer": function(input) {
            return (new Uint8Array(input)).buffer;
        },
        "uint8array": function(input) {
            return new Uint8Array(input);
        }
    },

    // arraybuffer to ?
    "arraybuffer": {
        "string": function(input) {
            return arrayLikeToString(new Uint8Array(input));
        },
        "array": function(input) {
            return arrayLikeToArrayLike(new Uint8Array(input), new Array(input.byteLength));
        },
        "arraybuffer": identity,
        "uint8array": function(input) {
            return new Uint8Array(input);
        }
    },

    // uint8array to ?
    "uint8array": {
        "string": arrayLikeToString,
        "array": function(input) {
            return arrayLikeToArrayLike(input, new Array(input.length));
        },
        "arraybuffer": function(input) {
            return input.buffer;
        },
        "uint8array": identity
    }
};

/**
 * Transform an input into any type.
 * The supported output type are : string, array, uint8array, arraybuffer.
 * If no output type is specified, the unmodified input will be returned.
 * @param {String} outputType the output type.
 * @param {String|Array|ArrayBuffer|Uint8Array|Buffer} input the input to convert.
 * @throws {Error} an Error if the browser doesn't support the requested output type.
 */
var transformTo = function(outputType, input) {
    if (!input) {
        // undefined, null, etc
        // an empty string won't harm.
        input = "";
    }
    if (!outputType) {
        return input;
    }
    checkSupport(outputType);
    var inputType = getTypeOf(input);
    var result = transform[inputType][outputType](input);
    return result;
};

/**
 * Return the type of the input.
 * The type will be in a format valid for JSZip.utils.transformTo : string, array, uint8array, arraybuffer.
 * @param {Object} input the input to identify.
 * @return {String} the (lowercase) type of the input.
 */
var getTypeOf = function(input) {
    if (typeof input === "string") {
        return "string";
    }
    if (Object.prototype.toString.call(input) === "[object Array]") {
        return "array";
    }
    if (support.uint8array && input instanceof Uint8Array) {
        return "uint8array";
    }
    if (support.arraybuffer && input instanceof ArrayBuffer) {
        return "arraybuffer";
    }
};

/**
 * Throw an exception if the type is not supported.
 * @param {String} type the type to check.
 * @throws {Error} an Error if the browser doesn't support the requested type.
 */
var checkSupport = function(type) {
    var supported = support[type.toLowerCase()];
    if (!supported) {
        throw new Error(type + " is not supported by this platform");
    }
};

var MAX_VALUE_16BITS = 65535;
var MAX_VALUE_32BITS = -1; // well, "\xFF\xFF\xFF\xFF\xFF\xFF\xFF\xFF" is parsed as -1

/**
 * Prettify a string read as binary.
 * @param {string} str the string to prettify.
 * @return {string} a pretty string.
 */
var pretty = function(str) {
    var res = '',
        code, i;
    for (i = 0; i < (str || "").length; i++) {
        code = str.charCodeAt(i);
        res += '\\x' + (code < 16 ? "0" : "") + code.toString(16).toUpperCase();
    }
    return res;
};

/**
 * Defer the call of a function.
 * @param {Function} callback the function to call asynchronously.
 * @param {Array} args the arguments to give to the callback.
 */
var delay = function(callback, args, self) {
    setTimeout(function() {
        callback.apply(self || null, args || []);
    }, 0);
};

/**
 * Merge the objects passed as parameters into a new one.
 * @private
 * @param {...Object} var_args All objects to merge.
 * @return {Object} a new object with the data of the others.
 */
var extend = function() {
    var arguments$1 = arguments;

    var result = {}, i, attr;
    for (i = 0; i < arguments.length; i++) { // arguments is not enumerable in some browsers
        for (attr in arguments[i]) {
            if (Object.hasOwnProperty.call(arguments$1[i], attr) && typeof result[attr] === "undefined") {
                result[attr] = arguments$1[i][attr];
            }
        }
    }
    return result;
};

/**
 * Transform arbitrary content into a Promise.
 * @param {String} name a name for the content being processed.
 * @param {Object} inputData the content to process.
 * @param {Boolean} isBinary true if the content is not an unicode string
 * @param {Boolean} isOptimizedBinaryString true if the string content only has one byte per character.
 * @param {Boolean} isBase64 true if the string content is encoded with base64.
 * @return {Promise} a promise in a format usable by JSZip.
 */
var prepareContent = function(name, inputData, isBinary, isOptimizedBinaryString, isBase64) {

    // if inputData is already a promise, this flatten it.
    var promise = external.Promise.resolve(inputData).then(function(data) {


        var isBlob = support.blob && (data instanceof Blob || ['[object File]', '[object Blob]'].indexOf(Object.prototype.toString.call(data)) !== -1);

        if (isBlob && typeof FileReader !== "undefined") {
            return new external.Promise(function (resolve, reject) {
                var reader = new FileReader();

                reader.onload = function(e) {
                    resolve(e.target.result);
                };
                reader.onerror = function(e) {
                    reject(e.target.error);
                };
                reader.readAsArrayBuffer(data);
            });
        } else {
            return data;
        }
    });

    return promise.then(function(data) {
        var dataType = getTypeOf(data);

        if (!dataType) {
            return external.Promise.reject(
                new Error("Can't read the data of '" + name + "'. Is it " +
                          "in a supported JavaScript type (String, Blob, ArrayBuffer, etc) ?")
            );
        }
        // special case : it's way easier to work with Uint8Array than with ArrayBuffer
        if (dataType === "arraybuffer") {
            data = transformTo("uint8array", data);
        } else if (dataType === "string") {
            if (isBase64) {
                data = decode(data);
            }
            else if (isBinary) {
                // optimizedBinaryString === true means that the file has already been filtered with a 0xFF mask
                if (isOptimizedBinaryString !== true) {
                    // this is a string, not in a base64 format.
                    // Be sure that this is a correct "binary string"
                    data = string2binary(data);
                }
            }
        }
        return data;
    });
};

/* eslint-disable */

/**
 * A worker that does nothing but passing chunks to the next one. This is like
 * a nodejs stream but with some differences. On the good side :
 * - it works on IE 6-9 without any issue / polyfill
 * - it weights less than the full dependencies bundled with browserify
 * - it forwards errors (no need to declare an error handler EVERYWHERE)
 *
 * A chunk is an object with 2 attributes : `meta` and `data`. The former is an
 * object containing anything (`percent` for example), see each worker for more
 * details. The latter is the real data (String, Uint8Array, etc).
 *
 * @constructor
 * @param {String} name the name of the stream (mainly used for debugging purposes)
 */
var GenericWorker = function GenericWorker(name) {
    // the name of the worker
    this.name = name || "default";
    // an object containing metadata about the workers chain
    this.streamInfo = {};
    // an error which happened when the worker was paused
    this.generatedError = null;
    // an object containing metadata to be merged by this worker into the general metadata
    this.extraStreamInfo = {};
    // true if the stream is paused (and should not do anything), false otherwise
    this.isPaused = true;
    // true if the stream is finished (and should not do anything), false otherwise
    this.isFinished = false;
    // true if the stream is locked to prevent further structure updates (pipe), false otherwise
    this.isLocked = false;
    // the event listeners
    this._listeners = {
        'data':[],
        'end':[],
        'error':[]
    };
    // the previous worker, if any
    this.previous = null;
};

/**
 * Push a chunk to the next workers.
 * @param {Object} chunk the chunk to push
 */
GenericWorker.prototype.push = function push (chunk) {
    this.emit("data", chunk);
};

/**
 * End the stream.
 * @return {Boolean} true if this call ended the worker, false otherwise.
 */
GenericWorker.prototype.end = function end () {
    if (this.isFinished) {
        return false;
    }

    this.flush();
    try {
        this.emit("end");
        this.cleanUp();
        this.isFinished = true;
    } catch (e) {
        this.emit("error", e);
    }
    return true;
};

/**
 * End the stream with an error.
 * @param {Error} e the error which caused the premature end.
 * @return {Boolean} true if this call ended the worker with an error, false otherwise.
 */
GenericWorker.prototype.error = function error (e) {
    if (this.isFinished) {
        return false;
    }

    if(this.isPaused) {
        this.generatedError = e;
    } else {
        this.isFinished = true;

        this.emit("error", e);

        // in the workers chain exploded in the middle of the chain,
        // the error event will go downward but we also need to notify
        // workers upward that there has been an error.
        if(this.previous) {
            this.previous.error(e);
        }

        this.cleanUp();
    }
    return true;
};

/**
 * Add a callback on an event.
 * @param {String} name the name of the event (data, end, error)
 * @param {Function} listener the function to call when the event is triggered
 * @return {GenericWorker} the current object for chainability
 */
GenericWorker.prototype.on = function on (name, listener) {
    this._listeners[name].push(listener);
    return this;
};

/**
 * Clean any references when a worker is ending.
 */
GenericWorker.prototype.cleanUp = function cleanUp () {
    this.streamInfo = this.generatedError = this.extraStreamInfo = null;
    this._listeners = [];
};

/**
 * Trigger an event. This will call registered callback with the provided arg.
 * @param {String} name the name of the event (data, end, error)
 * @param {Object} arg the argument to call the callback with.
 */
GenericWorker.prototype.emit = function emit (name, arg) {
    if (this._listeners[name]) {
        for(var i = 0; i < this._listeners[name].length; i++) {
            this._listeners[name][i].call(this, arg);
        }
    }
};

/**
 * Chain a worker with an other.
 * @param {Worker} next the worker receiving events from the current one.
 * @return {worker} the next worker for chainability
 */
GenericWorker.prototype.pipe = function pipe (next) {
    return next.registerPrevious(this);
};

/**
 * Same as `pipe` in the other direction.
 * Using an API with `pipe(next)` is very easy.
 * Implementing the API with the point of view of the next one registering
 * a source is easier, see the ZipFileWorker.
 * @param {Worker} previous the previous worker, sending events to this one
 * @return {Worker} the current worker for chainability
 */
GenericWorker.prototype.registerPrevious = function registerPrevious (previous) {
    if (this.isLocked) {
        throw new Error("The stream '" + this + "' has already been used.");
    }

    // sharing the streamInfo...
    this.streamInfo = previous.streamInfo;
    // ... and adding our own bits
    this.mergeStreamInfo();
    this.previous =  previous;
    var self = this;
    previous.on('data', function (chunk) {
        self.processChunk(chunk);
    });
    previous.on('end', function () {
        self.end();
    });
    previous.on('error', function (e) {
        self.error(e);
    });
    return this;
};

/**
 * Pause the stream so it doesn't send events anymore.
 * @return {Boolean} true if this call paused the worker, false otherwise.
 */
GenericWorker.prototype.pause = function pause () {
    if(this.isPaused || this.isFinished) {
        return false;
    }
    this.isPaused = true;

    if(this.previous) {
        this.previous.pause();
    }
    return true;
};

/**
 * Resume a paused stream.
 * @return {Boolean} true if this call resumed the worker, false otherwise.
 */
GenericWorker.prototype.resume = function resume () {
    if(!this.isPaused || this.isFinished) {
        return false;
    }
    this.isPaused = false;

    // if true, the worker tried to resume but failed
    var withError = false;
    if(this.generatedError) {
        this.error(this.generatedError);
        withError = true;
    }
    if(this.previous) {
        this.previous.resume();
    }

    return !withError;
};

/**
 * Flush any remaining bytes as the stream is ending.
 */
GenericWorker.prototype.flush = function flush () {};

/**
 * Process a chunk. This is usually the method overridden.
 * @param {Object} chunk the chunk to process.
 */
GenericWorker.prototype.processChunk = function processChunk (chunk) {
    this.push(chunk);
};

/**
 * Add a key/value to be added in the workers chain streamInfo once activated.
 * @param {String} key the key to use
 * @param {Object} value the associated value
 * @return {Worker} the current worker for chainability
 */
GenericWorker.prototype.withStreamInfo = function withStreamInfo (key, value) {
    this.extraStreamInfo[key] = value;
    this.mergeStreamInfo();
    return this;
};

/**
 * Merge this worker's streamInfo into the chain's streamInfo.
 */
GenericWorker.prototype.mergeStreamInfo = function mergeStreamInfo () {
    for(var key in this.extraStreamInfo) {
        if (!this.extraStreamInfo.hasOwnProperty(key)) {
            continue;
        }
        this.streamInfo[key] = this.extraStreamInfo[key];
    }
};

/**
 * Lock the stream to prevent further updates on the workers chain.
 * After calling this method, all calls to pipe will fail.
 */
GenericWorker.prototype.lock = function lock () {
    if (this.isLocked) {
        throw new Error("The stream '" + this + "' has already been used.");
    }
    this.isLocked = true;
    if (this.previous) {
        this.previous.lock();
    }
};

/**
 *
 * Pretty print the workers chain.
 */
GenericWorker.prototype.toString = function toString () {
    var me = "Worker " + this.name;
    if (this.previous) {
        return this.previous + " -> " + me;
    } else {
        return me;
    }
};

/* eslint-disable */

/**
 * The following functions come from pako, from pako/lib/utils/strings
 * released under the MIT license, see pako https://github.com/nodeca/pako/
 */

// Returns the utf8 lengths (calculated by first byte of sequence)
// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,
// because max possible codepoint is 0x10ffff
var utf8len = function(c) {
    var _utf8len = new Array(256);
    for (var i = 0; i < 256; i++) {
        _utf8len[i] = (i >= 252 ? 6 : i >= 248 ? 5 : i >= 240 ? 4 : i >= 224 ? 3 : i >= 192 ? 2 : 1);
    }
    _utf8len[254] = _utf8len[254] = 1; // Invalid sequence start

    // Memoize table after first call
    utf8len = function(c) {
        return _utf8len[c];
    };

    return _utf8len[c];
};

// convert string to array (typed, when possible)
var string2buf = function (str) {
    var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;

    // count binary size
    for (m_pos = 0; m_pos < str_len; m_pos++) {
        c = str.charCodeAt(m_pos);
        if ((c & 0xfc00) === 0xd800 && (m_pos+1 < str_len)) {
            c2 = str.charCodeAt(m_pos+1);
            if ((c2 & 0xfc00) === 0xdc00) {
                c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);
                m_pos++;
            }
        }
        buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;
    }

    // allocate buffer
    if (support.uint8array) {
        buf = new Uint8Array(buf_len);
    } else {
        buf = new Array(buf_len);
    }

    // convert
    for (i=0, m_pos = 0; i < buf_len; m_pos++) {
        c = str.charCodeAt(m_pos);
        if ((c & 0xfc00) === 0xd800 && (m_pos+1 < str_len)) {
            c2 = str.charCodeAt(m_pos+1);
            if ((c2 & 0xfc00) === 0xdc00) {
                c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);
                m_pos++;
            }
        }
        if (c < 0x80) {
            /* one byte */
            buf[i++] = c;
        } else if (c < 0x800) {
            /* two bytes */
            buf[i++] = 0xC0 | (c >>> 6);
            buf[i++] = 0x80 | (c & 0x3f);
        } else if (c < 0x10000) {
            /* three bytes */
            buf[i++] = 0xE0 | (c >>> 12);
            buf[i++] = 0x80 | (c >>> 6 & 0x3f);
            buf[i++] = 0x80 | (c & 0x3f);
        } else {
            /* four bytes */
            buf[i++] = 0xf0 | (c >>> 18);
            buf[i++] = 0x80 | (c >>> 12 & 0x3f);
            buf[i++] = 0x80 | (c >>> 6 & 0x3f);
            buf[i++] = 0x80 | (c & 0x3f);
        }
    }

    return buf;
};

// Calculate max possible position in utf8 buffer,
// that will not break sequence. If that's not possible
// - (very small limits) return max size as is.
//
// buf[] - utf8 bytes array
// max   - length limit (mandatory);
var utf8border = function(buf, max) {
    var pos;

    max = max || buf.length;
    if (max > buf.length) { max = buf.length; }

    // go back from last position, until start of sequence found
    pos = max-1;
    while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }

    // Fuckup - very small and broken sequence,
    // return max, because we should return something anyway.
    if (pos < 0) { return max; }

    // If we came to start of buffer - that means vuffer is too small,
    // return max too.
    if (pos === 0) { return max; }

    return (pos + utf8len(buf[pos]) > max) ? pos : max;
};

// convert array to string
var buf2string = function (buf) {
    var i, out, c, c_len;
    var len = buf.length;

    // Reserve max possible length (2 words per char)
    // NB: by unknown reasons, Array is significantly faster for
    //     String.fromCharCode.apply than Uint16Array.
    var utf16buf = new Array(len*2);

    for (out=0, i=0; i<len;) {
        c = buf[i++];
        // quick process ascii
        if (c < 0x80) { utf16buf[out++] = c; continue; }

        c_len = utf8len(c);
        // skip 5 & 6 byte codes
        if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len-1; continue; }

        // apply mask on first byte
        c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;
        // join the rest
        while (c_len > 1 && i < len) {
            c = (c << 6) | (buf[i++] & 0x3f);
            c_len--;
        }

        // terminated by end of string?
        if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }

        if (c < 0x10000) {
            utf16buf[out++] = c;
        } else {
            c -= 0x10000;
            utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);
            utf16buf[out++] = 0xdc00 | (c & 0x3ff);
        }
    }

    // shrinkBuf(utf16buf, out)
    if (utf16buf.length !== out) {
        if(utf16buf.subarray) {
            utf16buf = utf16buf.subarray(0, out);
        } else {
            utf16buf.length = out;
        }
    }

    // return String.fromCharCode.apply(null, utf16buf);
    return applyFromCharCode(utf16buf);
};


// That's all for the pako functions.


/**
 * Transform a javascript string into an array (typed if possible) of bytes,
 * UTF-8 encoded.
 * @param {String} str the string to encode
 * @return {Array|Uint8Array|Buffer} the UTF-8 encoded string.
 */
var utf8encode = function utf8encode(str) {
    return string2buf(str);
};

/**
 * Transform a bytes array (or a representation) representing an UTF-8 encoded
 * string into a javascript string.
 * @param {Array|Uint8Array|Buffer} buf the data de decode
 * @return {String} the decoded string.
 */
var utf8decode = function utf8decode(buf) {
    buf = transformTo(support.uint8array ? "uint8array" : "array", buf);

    return buf2string(buf);
};

/**
 * A worker to decode utf8 encoded binary chunks into string chunks.
 * @constructor
 */
var Utf8DecodeWorker = /*@__PURE__*/(function (GenericWorker) {
    function Utf8DecodeWorker() {
        GenericWorker.call(this, "utf-8 decode");

        // the last bytes if a chunk didn't end with a complete codepoint.
        this.leftOver = null;
    }

    if ( GenericWorker ) Utf8DecodeWorker.__proto__ = GenericWorker;
    Utf8DecodeWorker.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    Utf8DecodeWorker.prototype.constructor = Utf8DecodeWorker;

    /**
     * @see GenericWorker.processChunk
     */
    Utf8DecodeWorker.prototype.processChunk = function processChunk (chunk) {
        var data = transformTo(support.uint8array ? "uint8array" : "array", chunk.data);

        // 1st step, re-use what's left of the previous chunk
        if (this.leftOver && this.leftOver.length) {
            if(support.uint8array) {
                var previousData = data;
                data = new Uint8Array(previousData.length + this.leftOver.length);
                data.set(this.leftOver, 0);
                data.set(previousData, this.leftOver.length);
            } else {
                data = this.leftOver.concat(data);
            }
            this.leftOver = null;
        }

        var nextBoundary = utf8border(data);
        var usableData = data;
        if (nextBoundary !== data.length) {
            if (support.uint8array) {
                usableData = data.subarray(0, nextBoundary);
                this.leftOver = data.subarray(nextBoundary, data.length);
            } else {
                usableData = data.slice(0, nextBoundary);
                this.leftOver = data.slice(nextBoundary, data.length);
            }
        }

        this.push({
            data : utf8decode(usableData),
            meta : chunk.meta
        });
    };

    /**
     * @see GenericWorker.flush
     */
    Utf8DecodeWorker.prototype.flush = function flush () {
        if (this.leftOver && this.leftOver.length) {
            this.push({
                data : utf8decode(this.leftOver),
                meta : {}
            });
            this.leftOver = null;
        }
    };

    return Utf8DecodeWorker;
}(GenericWorker));

/**
 * A worker to endcode string chunks into utf8 encoded binary chunks.
 * @constructor
 */
var Utf8EncodeWorker = /*@__PURE__*/(function (GenericWorker) {
    function Utf8EncodeWorker() {
        GenericWorker.call(this, "utf-8 encode");
    }

    if ( GenericWorker ) Utf8EncodeWorker.__proto__ = GenericWorker;
    Utf8EncodeWorker.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    Utf8EncodeWorker.prototype.constructor = Utf8EncodeWorker;

    /**
     * @see GenericWorker.processChunk
     */
    Utf8EncodeWorker.prototype.processChunk = function processChunk (chunk) {
        this.push({
            data: utf8encode(chunk.data),
            meta: chunk.meta
        });
    };

    return Utf8EncodeWorker;
}(GenericWorker));

/**
 * A worker which convert chunks to a specified type.
 * @constructor
 * @param {String} destType the destination type.
 */
var ConvertWorker = /*@__PURE__*/(function (GenericWorker) {
    function ConvertWorker(destType) {
        GenericWorker.call(this, "ConvertWorker to " + destType);
        this.destType = destType;
    }

    if ( GenericWorker ) ConvertWorker.__proto__ = GenericWorker;
    ConvertWorker.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    ConvertWorker.prototype.constructor = ConvertWorker;

    /**
     * @see GenericWorker.processChunk
     */
    ConvertWorker.prototype.processChunk = function processChunk (chunk) {
        this.push({
            data: transformTo(this.destType, chunk.data),
            meta: chunk.meta
        });
    };

    return ConvertWorker;
}(GenericWorker));

/* eslint-disable */

/**
 * Apply the final transformation of the data. If the user wants a Blob for
 * example, it's easier to work with an U8intArray and finally do the
 * ArrayBuffer/Blob conversion.
 * @param {String} type the name of the final type
 * @param {String|Uint8Array|Buffer} content the content to transform
 * @param {String} mimeType the mime type of the content, if applicable.
 * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the content in the right format.
 */
function transformZipOutput(type, content, mimeType) {
    switch(type) {
        case "blob" :
            return newBlob(transformTo("arraybuffer", content), mimeType);
        case "base64" :
            return encode(content);
        default :
            return transformTo(type, content);
    }
}

/**
 * Concatenate an array of data of the given type.
 * @param {String} type the type of the data in the given array.
 * @param {Array} dataArray the array containing the data chunks to concatenate
 * @return {String|Uint8Array|Buffer} the concatenated data
 * @throws Error if the asked type is unsupported
 */
function concat (type, dataArray) {
    var i, index = 0, res = null, totalLength = 0;
    for(i = 0; i < dataArray.length; i++) {
        totalLength += dataArray[i].length;
    }
    switch(type) {
        case "string":
            return dataArray.join("");
          case "array":
            return Array.prototype.concat.apply([], dataArray);
        case "uint8array":
            res = new Uint8Array(totalLength);
            for(i = 0; i < dataArray.length; i++) {
                res.set(dataArray[i], index);
                index += dataArray[i].length;
            }
            return res;
        default:
            throw new Error("concat : unsupported type '"  + type + "'");
    }
}

/**
 * Listen a StreamHelper, accumulate its content and concatenate it into a
 * complete block.
 * @param {StreamHelper} helper the helper to use.
 * @param {Function} updateCallback a callback called on each update. Called
 * with one arg :
 * - the metadata linked to the update received.
 * @return Promise the promise for the accumulation.
 */
function accumulate(helper, updateCallback) {
    return new external.Promise(function (resolve, reject){
        var dataArray = [];
        var chunkType = helper._internalType,
            resultType = helper._outputType,
            mimeType = helper._mimeType;
        helper
        .on('data', function (data, meta) {
            dataArray.push(data);
            if(updateCallback) {
                updateCallback(meta);
            }
        })
        .on('error', function(err) {
            dataArray = [];
            reject(err);
        })
        .on('end', function (){
            try {
                var result = transformZipOutput(resultType, concat(chunkType, dataArray), mimeType);
                resolve(result);
            } catch (e) {
                reject(e);
            }
            dataArray = [];
        })
        .resume();
    });
}

/**
 * An helper to easily use workers outside of JSZip.
 * @constructor
 * @param {Worker} worker the worker to wrap
 * @param {String} outputType the type of data expected by the use
 * @param {String} mimeType the mime type of the content, if applicable.
 */
var StreamHelper = function StreamHelper (worker, outputType, mimeType) {
    var internalType = outputType;
    switch(outputType) {
        case "blob":
        case "arraybuffer":
            internalType = "uint8array";
        break;
        case "base64":
            internalType = "string";
        break;
    }

    try {
        // the type used internally
        this._internalType = internalType;
        // the type used to output results
        this._outputType = outputType;
        // the mime type
        this._mimeType = mimeType;
        checkSupport(internalType);
        this._worker = worker.pipe(new ConvertWorker(internalType));
        // the last workers can be rewired without issues but we need to
        // prevent any updates on previous workers.
        worker.lock();
    } catch(e) {
        this._worker = new GenericWorker("error");
        this._worker.error(e);
    }
};

/**
 * Listen a StreamHelper, accumulate its content and concatenate it into a
 * complete block.
 * @param {Function} updateCb the update callback.
 * @return Promise the promise for the accumulation.
 */
StreamHelper.prototype.accumulate = function accumulate$1 (updateCb) {
    return accumulate(this, updateCb);
};

/**
 * Add a listener on an event triggered on a stream.
 * @param {String} evt the name of the event
 * @param {Function} fn the listener
 * @return {StreamHelper} the current helper.
 */
StreamHelper.prototype.on = function on (evt, fn) {
    var self = this;

    if(evt === "data") {
        this._worker.on(evt, function (chunk) {
            fn.call(self, chunk.data, chunk.meta);
        });
    } else {
        this._worker.on(evt, function () {
            delay(fn, arguments, self);
        });
    }
    return this;
};

/**
 * Resume the flow of chunks.
 * @return {StreamHelper} the current helper.
 */
StreamHelper.prototype.resume = function resume () {
    delay(this._worker.resume, [], this._worker);
    return this;
};

/**
 * Pause the flow of chunks.
 * @return {StreamHelper} the current helper.
 */
StreamHelper.prototype.pause = function pause () {
    this._worker.pause();
    return this;
};

var base64 = false;
var binary = false;
var dir = false;
var createFolders = true;
var date = null;
var compression = null;
var compressionOptions = null;
var comment = null;
var unixPermissions = null;
var dosPermissions = null;

var defaults = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64,
    binary: binary,
    dir: dir,
    createFolders: createFolders,
    date: date,
    compression: compression,
    compressionOptions: compressionOptions,
    comment: comment,
    unixPermissions: unixPermissions,
    dosPermissions: dosPermissions
});

/* eslint-disable */

// the size of the generated chunks
// TODO expose this as a public variable
var DEFAULT_BLOCK_SIZE = 16 * 1024;

/**
 * A worker that reads a content and emits chunks.
 * @constructor
 * @param {Promise} dataP the promise of the data to split
 */
var DataWorker = /*@__PURE__*/(function (GenericWorker) {
    function DataWorker(dataP) {
        GenericWorker.call(this, "DataWorker");
        var self = this;
        this.dataIsReady = false;
        this.index = 0;
        this.max = 0;
        this.data = null;
        this.type = "";

        this._tickScheduled = false;

        dataP.then(function (data) {
            self.dataIsReady = true;
            self.data = data;
            self.max = data && data.length || 0;
            self.type = getTypeOf(data);
            if(!self.isPaused) {
                self._tickAndRepeat();
            }
        }, function (e) {
            self.error(e);
        });
    }

    if ( GenericWorker ) DataWorker.__proto__ = GenericWorker;
    DataWorker.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    DataWorker.prototype.constructor = DataWorker;

    /**
     * @see GenericWorker.cleanUp
     */
    DataWorker.prototype.cleanUp = function cleanUp () {
        GenericWorker.prototype.cleanUp.call(this);
        this.data = null;
    };

    /**
     * @see GenericWorker.resume
     */
    DataWorker.prototype.resume = function resume () {
        if(!GenericWorker.prototype.resume.call(this)) {
            return false;
        }

        if (!this._tickScheduled && this.dataIsReady) {
            this._tickScheduled = true;
            delay(this._tickAndRepeat, [], this);
        }
        return true;
    };

    /**
     * Trigger a tick a schedule an other call to this function.
     */
    DataWorker.prototype._tickAndRepeat = function _tickAndRepeat () {
        this._tickScheduled = false;
        if(this.isPaused || this.isFinished) {
            return;
        }
        this._tick();
        if(!this.isFinished) {
            delay(this._tickAndRepeat, [], this);
            this._tickScheduled = true;
        }
    };
    /**
     * Read and push a chunk.
     */
    DataWorker.prototype._tick = function _tick () {

        if(this.isPaused || this.isFinished) {
            return false;
        }

        var size = DEFAULT_BLOCK_SIZE;
        var data = null, nextIndex = Math.min(this.max, this.index + size);
        if (this.index >= this.max) {
            // EOF
            return this.end();
        } else {
            switch(this.type) {
                case "string":
                    data = this.data.substring(this.index, nextIndex);
                break;
                case "uint8array":
                    data = this.data.subarray(this.index, nextIndex);
                break;
                case "array":
                    data = this.data.slice(this.index, nextIndex);
                break;
            }
            this.index = nextIndex;
            return this.push({
                data : data,
                meta : {
                    percent : this.max ? this.index / this.max * 100 : 0
                }
            });
        }
    };

    return DataWorker;
}(GenericWorker));

/**
 * A worker which calculate the total length of the data flowing through.
 * @constructor
 * @param {String} propName the name used to expose the length
 */
var DataLengthProbe = /*@__PURE__*/(function (GenericWorker) {
    function DataLengthProbe(propName) {
        GenericWorker.call(this, "DataLengthProbe for " + propName);
        this.propName = propName;
        this.withStreamInfo(propName, 0);
    }

    if ( GenericWorker ) DataLengthProbe.__proto__ = GenericWorker;
    DataLengthProbe.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    DataLengthProbe.prototype.constructor = DataLengthProbe;

    /**
     * @see GenericWorker.processChunk
     */
    DataLengthProbe.prototype.processChunk = function processChunk (chunk) {
        if (chunk) {
            var length = this.streamInfo[this.propName] || 0;
            this.streamInfo[this.propName] = length + chunk.data.length;
        }
        GenericWorker.prototype.processChunk.call(this, chunk);
    };

    return DataLengthProbe;
}(GenericWorker));

/* eslint-disable */

/**
 * The following functions come from pako, from pako/lib/zlib/crc32.js
 * released under the MIT license, see pako https://github.com/nodeca/pako/
 */

var makeTable = function() {
    // Use ordinary array, since untyped makes no boost here
    var table = [];

    for (var n =0; n < 256; n++){
        var c = n;
        for(var k =0; k < 8; k++){
            c = ((c&1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));
        }
        table[n] = c;
    }

    // Memoize table on first call.
    makeTable = function() {
        return table;
    };

    return table;
};

function crc32(crc, buf, len, pos) {
    var t = makeTable();
    var end = pos + len;

    crc = crc ^ (-1);

    for (var i = pos; i < end; i++ ) {
        crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];
    }

    return (crc ^ (-1)); // >>> 0;
}

// That's all for the pako functions.

/**
 * Compute the crc32 of a string.
 * This is almost the same as the function crc32, but for strings. Using the
 * same function for the two use cases leads to horrible performances.
 * @param {Number} crc the starting value of the crc.
 * @param {String} str the string to use.
 * @param {Number} len the length of the string.
 * @param {Number} pos the starting position for the crc32 computation.
 * @return {Number} the computed crc32.
 */
function crc32str(crc, str, len, pos) {
    var t = makeTable();
    var end = pos + len;

    crc = crc ^ (-1);

    for (var i = pos; i < end; i++ ) {
        crc = (crc >>> 8) ^ t[(crc ^ str.charCodeAt(i)) & 0xFF];
    }

    return (crc ^ (-1)); // >>> 0;
}

function crc32wrapper(input, crc) {
    if (typeof input === "undefined" || !input.length) {
        return 0;
    }

    var isArray = getTypeOf(input) !== "string";

    if (isArray) {
        return crc32(crc | 0, input, input.length, 0);
    } else {
        return crc32str(crc | 0, input, input.length, 0);
    }
}

/**
 * A worker which calculate the crc32 of the data flowing through.
 * @constructor
 */
var Crc32Probe = /*@__PURE__*/(function (GenericWorker) {
    function Crc32Probe() {
        GenericWorker.call(this, "Crc32Probe");
        this.withStreamInfo("crc32", 0);
    }

    if ( GenericWorker ) Crc32Probe.__proto__ = GenericWorker;
    Crc32Probe.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    Crc32Probe.prototype.constructor = Crc32Probe;

    /**
     * @see GenericWorker.processChunk
     */
    Crc32Probe.prototype.processChunk = function processChunk (chunk) {
        this.streamInfo.crc32 = crc32wrapper(chunk.data, this.streamInfo.crc32 || 0);
        this.push(chunk);
    };

    return Crc32Probe;
}(GenericWorker));

/* eslint-disable */

/**
 * Represent a compressed object, with everything needed to decompress it.
 * @constructor
 * @param {number} compressedSize the size of the data compressed.
 * @param {number} uncompressedSize the size of the data after decompression.
 * @param {number} crc32 the crc32 of the decompressed file.
 * @param {object} compression the type of compression, see lib/compressions.js.
 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the compressed data.
 */
var CompressedObject = function CompressedObject(compressedSize, uncompressedSize, crc32, compression, data) {
    this.compressedSize = compressedSize;
    this.uncompressedSize = uncompressedSize;
    this.crc32 = crc32;
    this.compression = compression;
    this.compressedContent = data;
};

/**
 * Create a worker to get the uncompressed content.
 * @return {GenericWorker} the worker.
 */
CompressedObject.prototype.getContentWorker = function getContentWorker () {
    var worker = new DataWorker(external.Promise.resolve(this.compressedContent))
    .pipe(this.compression.uncompressWorker())
    .pipe(new DataLengthProbe("data_length"));

    var that = this;
    worker.on("end", function () {
        if(this.streamInfo['data_length'] !== that.uncompressedSize) {
            throw new Error("Bug : uncompressed data size mismatch");
        }
    });
    return worker;
};

/**
 * Create a worker to get the compressed content.
 * @return {GenericWorker} the worker.
 */
CompressedObject.prototype.getCompressedWorker = function getCompressedWorker () {
    return new DataWorker(external.Promise.resolve(this.compressedContent))
    .withStreamInfo("compressedSize", this.compressedSize)
    .withStreamInfo("uncompressedSize", this.uncompressedSize)
    .withStreamInfo("crc32", this.crc32)
    .withStreamInfo("compression", this.compression)
    ;
};

/**
 * Chain the given worker with other workers to compress the content with the
 * given compression.
 * @param {GenericWorker} uncompressedWorker the worker to pipe.
 * @param {Object} compression the compression object.
 * @param {Object} compressionOptions the options to use when compressing.
 * @return {GenericWorker} the new worker compressing the content.
 */
CompressedObject.createWorkerFrom = function createWorkerFrom (uncompressedWorker, compression, compressionOptions) {
    return uncompressedWorker
    .pipe(new Crc32Probe())
    .pipe(new DataLengthProbe("uncompressedSize"))
    .pipe(compression.compressWorker(compressionOptions))
    .pipe(new DataLengthProbe("compressedSize"))
    .withStreamInfo("compression", compression);
};

/* eslint-disable */

/**
 * A simple object representing a file in the zip file.
 * @constructor
 * @param {string} name the name of the file
 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data
 * @param {Object} options the options of the file
 */
var ZipObject = function ZipObject(name, data, options) {
    this.name = name;
    this.dir = options.dir;
    this.date = options.date;
    this.comment = options.comment;
    this.unixPermissions = options.unixPermissions;
    this.dosPermissions = options.dosPermissions;

    this._data = data;
    this._dataBinary = options.binary;
    // keep only the compression
    this.options = {
        compression : options.compression,
        compressionOptions : options.compressionOptions
    };
};

/**
 * Create an internal stream for the content of this object.
 * @param {String} type the type of each chunk.
 * @return StreamHelper the stream.
 */
ZipObject.prototype.internalStream = function internalStream (type) {
    var result = null, outputType = "string";
    try {
        if (!type) {
            throw new Error("No output type specified.");
        }
        outputType = type.toLowerCase();
        var askUnicodeString = outputType === "string" || outputType === "text";
        if (outputType === "binarystring" || outputType === "text") {
            outputType = "string";
        }
        result = this._decompressWorker();

        var isUnicodeString = !this._dataBinary;

        if (isUnicodeString && !askUnicodeString) {
            result = result.pipe(new Utf8EncodeWorker());
        }
        if (!isUnicodeString && askUnicodeString) {
            result = result.pipe(new Utf8DecodeWorker());
        }
    } catch (e) {
        result = new GenericWorker("error");
        result.error(e);
    }

    return new StreamHelper(result, outputType, "");
};

/**
 * Prepare the content in the asked type.
 * @param {String} type the type of the result.
 * @param {Function} onUpdate a function to call on each internal update.
 * @return Promise the promise of the result.
 */
ZipObject.prototype.async = function async (type, onUpdate) {
    return this.internalStream(type).accumulate(onUpdate);
};

/**
 * Return a worker for the compressed content.
 * @private
 * @param {Object} compression the compression object to use.
 * @param {Object} compressionOptions the options to use when compressing.
 * @return Worker the worker.
 */
ZipObject.prototype._compressWorker = function _compressWorker (compression, compressionOptions) {
    if (
        this._data instanceof CompressedObject &&
        this._data.compression.magic === compression.magic
    ) {
        return this._data.getCompressedWorker();
    } else {
        var result = this._decompressWorker();
        if(!this._dataBinary) {
            result = result.pipe(new Utf8EncodeWorker());
        }
        return CompressedObject.createWorkerFrom(result, compression, compressionOptions);
    }
};

/**
 * Return a worker for the decompressed content.
 * @private
 * @return Worker the worker.
 */
ZipObject.prototype._decompressWorker = function _decompressWorker () {
    if (this._data instanceof CompressedObject) {
        return this._data.getContentWorker();
    } else if (this._data instanceof GenericWorker) {
        return this._data;
    } else {
        return new DataWorker(this._data);
    }
};

var arrayType = function() {
    var useTypedArray = (typeof Uint8Array !== 'undefined') && (typeof Uint16Array !== 'undefined') && (typeof Uint32Array !== 'undefined');
    var resolved = useTypedArray ? "uint8array" : "array";

    arrayType = function() {
        return resolved;
    };
};

/**
 * Create a worker that uses pako to inflate/deflate.
 * @constructor
 * @param {String} action the name of the pako function to call : either "Deflate" or "Inflate".
 * @param {Object} options the options to use when (de)compressing.
 */
var FlateWorker = /*@__PURE__*/(function (GenericWorker) {
    function FlateWorker(action, options) {
        GenericWorker.call(this, "FlateWorker/" + action);

        this._pako = null;
        this._pakoAction = action;
        this._pakoOptions = options;
        // the `meta` object from the last chunk received
        // this allow this worker to pass around metadata
        this.meta = {};
    }

    if ( GenericWorker ) FlateWorker.__proto__ = GenericWorker;
    FlateWorker.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    FlateWorker.prototype.constructor = FlateWorker;

    /**
     * @see GenericWorker.processChunk
     */
    FlateWorker.prototype.processChunk = function processChunk (chunk) {
        this.meta = chunk.meta;
        if (this._pako === null) {
            this._createPako();
        }
        this._pako.push(transformTo(arrayType(), chunk.data), false);
    };

    /**
     * @see GenericWorker.flush
     */
    FlateWorker.prototype.flush = function flush () {
        GenericWorker.prototype.flush.call(this);
        if (this._pako === null) {
            this._createPako();
        }
        this._pako.push([], true);
    };
    /**
     * @see GenericWorker.cleanUp
     */
    FlateWorker.prototype.cleanUp = function cleanUp () {
        GenericWorker.prototype.cleanUp.call(this);
        this._pako = null;
    };

    /**
     * Create the _pako object.
     * TODO: lazy-loading this object isn't the best solution but it's the
     * quickest. The best solution is to lazy-load the worker list. See also the
     * issue #446.
     */
    FlateWorker.prototype._createPako = function _createPako () {
        var this$1$1 = this;

        var params = {
            raw: true,
            level: this._pakoOptions.level || -1 // default compression
        };
        this._pako = this._pakoAction === 'Deflate' ? new Deflate(params) : new Inflate(params);
        this._pako.onData = function (data) {
            this$1$1.push({
                data: data,
                meta: this$1$1.meta
            });
        };
    };

    return FlateWorker;
}(GenericWorker));

var DEFLATE = {
    magic: "\x08\x00",
    compressWorker: function(compressionOptions) {
        return new FlateWorker("Deflate", compressionOptions);
    },

    uncompressWorker: function() {
        return new FlateWorker("Inflate", {});
    }
};

var STORE = {
    magic: "\x00\x00",
    compressWorker: function() {
        return new GenericWorker("STORE compression");
    },
    uncompressWorker: function() {
        return new GenericWorker("STORE decompression");
    }
};

var compressions = {
    STORE: STORE,
    DEFLATE: DEFLATE
};

var LOCAL_FILE_HEADER = "PK\x03\x04";
var CENTRAL_FILE_HEADER = "PK\x01\x02";
var CENTRAL_DIRECTORY_END = "PK\x05\x06";
var ZIP64_CENTRAL_DIRECTORY_LOCATOR = "PK\x06\x07";
var ZIP64_CENTRAL_DIRECTORY_END = "PK\x06\x06";
var DATA_DESCRIPTOR = "PK\x07\x08";

/* eslint-disable */

/**
 * Transform an integer into a string in hexadecimal.
 * @private
 * @param {number} dec the number to convert.
 * @param {number} bytes the number of bytes to generate.
 * @returns {string} the result.
 */
var decToHex = function(dec, bytes) {
    var hex = "", i;
    for (i = 0; i < bytes; i++) {
        hex += String.fromCharCode(dec & 0xff);
        dec = dec >>> 8;
    }
    return hex;
};

/**
 * Generate the UNIX part of the external file attributes.
 * @param {Object} unixPermissions the unix permissions or null.
 * @param {Boolean} isDir true if the entry is a directory, false otherwise.
 * @return {Number} a 32 bit integer.
 *
 * adapted from http://unix.stackexchange.com/questions/14705/the-zip-formats-external-file-attribute :
 *
 * TTTTsstrwxrwxrwx0000000000ADVSHR
 * ^^^^____________________________ file type, see zipinfo.c (UNX_*)
 *     ^^^_________________________ setuid, setgid, sticky
 *        ^^^^^^^^^________________ permissions
 *                 ^^^^^^^^^^______ not used ?
 *                           ^^^^^^ DOS attribute bits : Archive, Directory, Volume label, System file, Hidden, Read only
 */
var generateUnixExternalFileAttr = function (unixPermissions, isDir) {

    var result = unixPermissions;
    if (!unixPermissions) {
        // I can't use octal values in strict mode, hence the hexa.
        //  040775 => 0x41fd
        // 0100664 => 0x81b4
        result = isDir ? 0x41fd : 0x81b4;
    }
    return (result & 0xFFFF) << 16;
};

/**
 * Generate the DOS part of the external file attributes.
 * @param {Object} dosPermissions the dos permissions or null.
 * @param {Boolean} isDir true if the entry is a directory, false otherwise.
 * @return {Number} a 32 bit integer.
 *
 * Bit 0     Read-Only
 * Bit 1     Hidden
 * Bit 2     System
 * Bit 3     Volume Label
 * Bit 4     Directory
 * Bit 5     Archive
 */
var generateDosExternalFileAttr = function (dosPermissions, isDir) {

    // the dir flag is already set for compatibility
    return (dosPermissions || 0)  & 0x3F;
};

/**
 * Generate the various parts used in the construction of the final zip file.
 * @param {Object} streamInfo the hash with information about the compressed file.
 * @param {Boolean} streamedContent is the content streamed ?
 * @param {Boolean} streamingEnded is the stream finished ?
 * @param {number} offset the current offset from the start of the zip file.
 * @param {String} platform let's pretend we are this platform (change platform dependents fields)
 * @param {Function} encodeFileName the function to encode the file name / comment.
 * @return {Object} the zip parts.
 */
var generateZipParts = function(streamInfo, streamedContent, streamingEnded, offset, platform, encodeFileName) {
    var file = streamInfo['file'],
    compression = streamInfo['compression'],
    useCustomEncoding = encodeFileName !== utf8encode,
    encodedFileName = transformTo("string", encodeFileName(file.name)),
    utfEncodedFileName = transformTo("string", utf8encode(file.name)),
    comment = file.comment,
    encodedComment = transformTo("string", encodeFileName(comment)),
    utfEncodedComment = transformTo("string", utf8encode(comment)),
    useUTF8ForFileName = utfEncodedFileName.length !== file.name.length,
    useUTF8ForComment = utfEncodedComment.length !== comment.length,
    dosTime,
    dosDate,
    extraFields = "",
    unicodePathExtraField = "",
    unicodeCommentExtraField = "",
    dir = file.dir,
    date = file.date;


    var dataInfo = {
        crc32 : 0,
        compressedSize : 0,
        uncompressedSize : 0
    };

    // if the content is streamed, the sizes/crc32 are only available AFTER
    // the end of the stream.
    if (!streamedContent || streamingEnded) {
        dataInfo.crc32 = streamInfo['crc32'];
        dataInfo.compressedSize = streamInfo['compressedSize'];
        dataInfo.uncompressedSize = streamInfo['uncompressedSize'];
    }

    var bitflag = 0;
    if (streamedContent) {
        // Bit 3: the sizes/crc32 are set to zero in the local header.
        // The correct values are put in the data descriptor immediately
        // following the compressed data.
        bitflag |= 0x0008;
    }
    if (!useCustomEncoding && (useUTF8ForFileName || useUTF8ForComment)) {
        // Bit 11: Language encoding flag (EFS).
        bitflag |= 0x0800;
    }


    var extFileAttr = 0;
    var versionMadeBy = 0;
    if (dir) {
        // dos or unix, we set the dos dir flag
        extFileAttr |= 0x00010;
    }
    if(platform === "UNIX") {
        versionMadeBy = 0x031E; // UNIX, version 3.0
        extFileAttr |= generateUnixExternalFileAttr(file.unixPermissions, dir);
    } else { // DOS or other, fallback to DOS
        versionMadeBy = 0x0014; // DOS, version 2.0
        extFileAttr |= generateDosExternalFileAttr(file.dosPermissions);
    }

    // date
    // @see http://www.delorie.com/djgpp/doc/rbinter/it/52/13.html
    // @see http://www.delorie.com/djgpp/doc/rbinter/it/65/16.html
    // @see http://www.delorie.com/djgpp/doc/rbinter/it/66/16.html

    dosTime = date.getUTCHours();
    dosTime = dosTime << 6;
    dosTime = dosTime | date.getUTCMinutes();
    dosTime = dosTime << 5;
    dosTime = dosTime | date.getUTCSeconds() / 2;

    dosDate = date.getUTCFullYear() - 1980;
    dosDate = dosDate << 4;
    dosDate = dosDate | (date.getUTCMonth() + 1);
    dosDate = dosDate << 5;
    dosDate = dosDate | date.getUTCDate();

    if (useUTF8ForFileName) {
        // set the unicode path extra field. unzip needs at least one extra
        // field to correctly handle unicode path, so using the path is as good
        // as any other information. This could improve the situation with
        // other archive managers too.
        // This field is usually used without the utf8 flag, with a non
        // unicode path in the header (winrar, winzip). This helps (a bit)
        // with the messy Windows' default compressed folders feature but
        // breaks on p7zip which doesn't seek the unicode path extra field.
        // So for now, UTF-8 everywhere !
        unicodePathExtraField =
            // Version
            decToHex(1, 1) +
            // NameCRC32
            decToHex(crc32wrapper(encodedFileName), 4) +
            // UnicodeName
            utfEncodedFileName;

        extraFields +=
            // Info-ZIP Unicode Path Extra Field
            "\x75\x70" +
            // size
            decToHex(unicodePathExtraField.length, 2) +
            // content
            unicodePathExtraField;
    }

    if(useUTF8ForComment) {

        unicodeCommentExtraField =
            // Version
            decToHex(1, 1) +
            // CommentCRC32
            decToHex(crc32wrapper(encodedComment), 4) +
            // UnicodeName
            utfEncodedComment;

        extraFields +=
            // Info-ZIP Unicode Path Extra Field
            "\x75\x63" +
            // size
            decToHex(unicodeCommentExtraField.length, 2) +
            // content
            unicodeCommentExtraField;
    }

    var header = "";

    // version needed to extract
    header += "\x0A\x00";
    // general purpose bit flag
    header += decToHex(bitflag, 2);
    // compression method
    header += compression.magic;
    // last mod file time
    header += decToHex(dosTime, 2);
    // last mod file date
    header += decToHex(dosDate, 2);
    // crc-32
    header += decToHex(dataInfo.crc32, 4);
    // compressed size
    header += decToHex(dataInfo.compressedSize, 4);
    // uncompressed size
    header += decToHex(dataInfo.uncompressedSize, 4);
    // file name length
    header += decToHex(encodedFileName.length, 2);
    // extra field length
    header += decToHex(extraFields.length, 2);


    var fileRecord = LOCAL_FILE_HEADER + header + encodedFileName + extraFields;

    var dirRecord = CENTRAL_FILE_HEADER +
        // version made by (00: DOS)
        decToHex(versionMadeBy, 2) +
        // file header (common to file and central directory)
        header +
        // file comment length
        decToHex(encodedComment.length, 2) +
        // disk number start
        "\x00\x00" +
        // internal file attributes TODO
        "\x00\x00" +
        // external file attributes
        decToHex(extFileAttr, 4) +
        // relative offset of local header
        decToHex(offset, 4) +
        // file name
        encodedFileName +
        // extra field
        extraFields +
        // file comment
        encodedComment;

    return {
        fileRecord: fileRecord,
        dirRecord: dirRecord
    };
};

/**
 * Generate the EOCD record.
 * @param {Number} entriesCount the number of entries in the zip file.
 * @param {Number} centralDirLength the length (in bytes) of the central dir.
 * @param {Number} localDirLength the length (in bytes) of the local dir.
 * @param {String} comment the zip file comment as a binary string.
 * @param {Function} encodeFileName the function to encode the comment.
 * @return {String} the EOCD record.
 */
var generateCentralDirectoryEnd = function (entriesCount, centralDirLength, localDirLength, comment, encodeFileName) {
    var dirEnd = "";
    var encodedComment = transformTo("string", encodeFileName(comment));

    // end of central dir signature
    dirEnd = CENTRAL_DIRECTORY_END +
        // number of this disk
        "\x00\x00" +
        // number of the disk with the start of the central directory
        "\x00\x00" +
        // total number of entries in the central directory on this disk
        decToHex(entriesCount, 2) +
        // total number of entries in the central directory
        decToHex(entriesCount, 2) +
        // size of the central directory   4 bytes
        decToHex(centralDirLength, 4) +
        // offset of start of central directory with respect to the starting disk number
        decToHex(localDirLength, 4) +
        // .ZIP file comment length
        decToHex(encodedComment.length, 2) +
        // .ZIP file comment
        encodedComment;

    return dirEnd;
};

/**
 * Generate data descriptors for a file entry.
 * @param {Object} streamInfo the hash generated by a worker, containing information
 * on the file entry.
 * @return {String} the data descriptors.
 */
var generateDataDescriptors = function (streamInfo) {
    var descriptor = "";
    descriptor = DATA_DESCRIPTOR +
        // crc-32                          4 bytes
        decToHex(streamInfo['crc32'], 4) +
        // compressed size                 4 bytes
        decToHex(streamInfo['compressedSize'], 4) +
        // uncompressed size               4 bytes
        decToHex(streamInfo['uncompressedSize'], 4);

    return descriptor;
};


/**
 * A worker to concatenate other workers to create a zip file.
 * @param {Boolean} streamFiles `true` to stream the content of the files,
 * `false` to accumulate it.
 * @param {String} comment the comment to use.
 * @param {String} platform the platform to use, "UNIX" or "DOS".
 * @param {Function} encodeFileName the function to encode file names and comments.
 */
var ZipFileWorker = /*@__PURE__*/(function (GenericWorker) {
    function ZipFileWorker(streamFiles, comment, platform, encodeFileName) {
        GenericWorker.call(this, "ZipFileWorker");
        // The number of bytes written so far. This doesn't count accumulated chunks.
        this.bytesWritten = 0;
        // The comment of the zip file
        this.zipComment = comment;
        // The platform "generating" the zip file.
        this.zipPlatform = platform;
        // the function to encode file names and comments.
        this.encodeFileName = encodeFileName;
        // Should we stream the content of the files ?
        this.streamFiles = streamFiles;
        // If `streamFiles` is false, we will need to accumulate the content of the
        // files to calculate sizes / crc32 (and write them *before* the content).
        // This boolean indicates if we are accumulating chunks (it will change a lot
        // during the lifetime of this worker).
        this.accumulate = false;
        // The buffer receiving chunks when accumulating content.
        this.contentBuffer = [];
        // The list of generated directory records.
        this.dirRecords = [];
        // The offset (in bytes) from the beginning of the zip file for the current source.
        this.currentSourceOffset = 0;
        // The total number of entries in this zip file.
        this.entriesCount = 0;
        // the name of the file currently being added, null when handling the end of the zip file.
        // Used for the emitted metadata.
        this.currentFile = null;

        this._sources = [];
    }

    if ( GenericWorker ) ZipFileWorker.__proto__ = GenericWorker;
    ZipFileWorker.prototype = Object.create( GenericWorker && GenericWorker.prototype );
    ZipFileWorker.prototype.constructor = ZipFileWorker;

    /**
     * @see GenericWorker.push
     */
    ZipFileWorker.prototype.push = function push (chunk) {

        var currentFilePercent = chunk.meta.percent || 0;
        var entriesCount = this.entriesCount;
        var remainingFiles = this._sources.length;

        if(this.accumulate) {
            this.contentBuffer.push(chunk);
        } else {
            this.bytesWritten += chunk.data.length;

            GenericWorker.prototype.push.call(this, {
                data : chunk.data,
                meta : {
                    currentFile : this.currentFile,
                    percent : entriesCount ? (currentFilePercent + 100 * (entriesCount - remainingFiles - 1)) / entriesCount : 100
                }
            });
        }
    };

    /**
     * The worker started a new source (an other worker).
     * @param {Object} streamInfo the streamInfo object from the new source.
     */
    ZipFileWorker.prototype.openedSource = function openedSource (streamInfo) {
        this.currentSourceOffset = this.bytesWritten;
        this.currentFile = streamInfo['file'].name;

        var streamedContent = this.streamFiles && !streamInfo['file'].dir;

        // don't stream folders (because they don't have any content)
        if(streamedContent) {
            var record = generateZipParts(streamInfo, streamedContent, false, this.currentSourceOffset, this.zipPlatform, this.encodeFileName);
            this.push({
                data : record.fileRecord,
                meta : {percent:0}
            });
        } else {
            // we need to wait for the whole file before pushing anything
            this.accumulate = true;
        }
    };

    /**
     * The worker finished a source (an other worker).
     * @param {Object} streamInfo the streamInfo object from the finished source.
     */
    ZipFileWorker.prototype.closedSource = function closedSource (streamInfo) {
        this.accumulate = false;
        var streamedContent = this.streamFiles && !streamInfo['file'].dir;
        var record = generateZipParts(streamInfo, streamedContent, true, this.currentSourceOffset, this.zipPlatform, this.encodeFileName);

        this.dirRecords.push(record.dirRecord);
        if(streamedContent) {
            // after the streamed file, we put data descriptors
            this.push({
                data : generateDataDescriptors(streamInfo),
                meta : {percent:100}
            });
        } else {
            // the content wasn't streamed, we need to push everything now
            // first the file record, then the content
            this.push({
                data : record.fileRecord,
                meta : {percent:0}
            });
            while(this.contentBuffer.length) {
                this.push(this.contentBuffer.shift());
            }
        }
        this.currentFile = null;
    };

    /**
     * @see GenericWorker.flush
     */
    ZipFileWorker.prototype.flush = function flush () {

        var localDirLength = this.bytesWritten;
        for(var i = 0; i < this.dirRecords.length; i++) {
            this.push({
                data : this.dirRecords[i],
                meta : {percent:100}
            });
        }
        var centralDirLength = this.bytesWritten - localDirLength;

        var dirEnd = generateCentralDirectoryEnd(this.dirRecords.length, centralDirLength, localDirLength, this.zipComment, this.encodeFileName);

        this.push({
            data : dirEnd,
            meta : {percent:100}
        });
    };

    /**
     * Prepare the next source to be read.
     */
    ZipFileWorker.prototype.prepareNextSource = function prepareNextSource () {
        this.previous = this._sources.shift();
        this.openedSource(this.previous.streamInfo);
        if (this.isPaused) {
            this.previous.pause();
        } else {
            this.previous.resume();
        }
    };

    /**
     * @see GenericWorker.registerPrevious
     */
    ZipFileWorker.prototype.registerPrevious = function registerPrevious (previous) {
        this._sources.push(previous);
        var self = this;

        previous.on('data', function (chunk) {
            self.processChunk(chunk);
        });
        previous.on('end', function () {
            self.closedSource(self.previous.streamInfo);
            if(self._sources.length) {
                self.prepareNextSource();
            } else {
                self.end();
            }
        });
        previous.on('error', function (e) {
            self.error(e);
        });
        return this;
    };

    /**
     * @see GenericWorker.resume
     */
    ZipFileWorker.prototype.resume = function resume () {
        if(!GenericWorker.prototype.resume.call(this)) {
            return false;
        }

        if (!this.previous && this._sources.length) {
            this.prepareNextSource();
            return true;
        }
        if (!this.previous && !this._sources.length && !this.generatedError) {
            this.end();
            return true;
        }
    };

    /**
     * @see GenericWorker.error
     */
    ZipFileWorker.prototype.error = function error (e) {
        var sources = this._sources;
        if(!GenericWorker.prototype.error.call(this, e)) {
            return false;
        }
        for(var i = 0; i < sources.length; i++) {
            try {
                sources[i].error(e);
            } catch(e$1) {
                // the `error` exploded, nothing to do
            }
        }
        return true;
    };

    /**
     * @see GenericWorker.lock
     */
    ZipFileWorker.prototype.lock = function lock () {
        GenericWorker.prototype.lock.call(this);
        var sources = this._sources;
        for(var i = 0; i < sources.length; i++) {
            sources[i].lock();
        }
    };

    return ZipFileWorker;
}(GenericWorker));

/* eslint-disable */

/**
 * Find the compression to use.
 * @param {String} fileCompression the compression defined at the file level, if any.
 * @param {String} zipCompression the compression defined at the load() level.
 * @return {Object} the compression object to use.
 */
var getCompression = function (fileCompression, zipCompression) {

    var compressionName = fileCompression || zipCompression;
    var compression = compressions[compressionName];
    if (!compression) {
        throw new Error(compressionName + " is not a valid compression method !");
    }
    return compression;
};

/**
 * Create a worker to generate a zip file.
 * @param {JSZip} zip the JSZip instance at the right root level.
 * @param {Object} options to generate the zip file.
 * @param {String} comment the comment to use.
 */
var generateWorker = function (zip, options, comment) {

    var zipFileWorker = new ZipFileWorker(options.streamFiles, comment, options.platform, options.encodeFileName);
    var entriesCount = 0;
    try {

        zip.forEach(function (relativePath, file) {
            entriesCount++;
            var compression = getCompression(file.options.compression, options.compression);
            var compressionOptions = file.options.compressionOptions || options.compressionOptions || {};
            var dir = file.dir, date = file.date;

            file._compressWorker(compression, compressionOptions)
            .withStreamInfo("file", {
                name : relativePath,
                dir : dir,
                date : date,
                comment : file.comment || "",
                unixPermissions : file.unixPermissions,
                dosPermissions : file.dosPermissions
            })
            .pipe(zipFileWorker);
        });
        zipFileWorker.entriesCount = entriesCount;
    } catch (e) {
        zipFileWorker.error(e);
    }

    return zipFileWorker;
};

/* eslint-disable */

var DataReader = function DataReader(data) {
    this.data = data; // type : see implementation
    this.length = data.length;
    this.index = 0;
    this.zero = 0;
};

/**
 * Check that the offset will not go too far.
 * @param {string} offset the additional offset to check.
 * @throws {Error} an Error if the offset is out of bounds.
 */
DataReader.prototype.checkOffset = function checkOffset (offset) {
    this.checkIndex(this.index + offset);
};

/**
 * Check that the specified index will not be too far.
 * @param {string} newIndex the index to check.
 * @throws {Error} an Error if the index is out of bounds.
 */
DataReader.prototype.checkIndex = function checkIndex (newIndex) {
    if (this.length < this.zero + newIndex || newIndex < 0) {
        throw new Error("End of data reached (data length = " + this.length + ", asked index = " + (newIndex) + "). Corrupted zip ?");
    }
};

/**
 * Change the index.
 * @param {number} newIndex The new index.
 * @throws {Error} if the new index is out of the data.
 */
DataReader.prototype.setIndex = function setIndex (newIndex) {
    this.checkIndex(newIndex);
    this.index = newIndex;
};

/**
 * Skip the next n bytes.
 * @param {number} n the number of bytes to skip.
 * @throws {Error} if the new index is out of the data.
 */
DataReader.prototype.skip = function skip (n) {
    this.setIndex(this.index + n);
};

/**
 * Get the byte at the specified index.
 * @param {number} i the index to use.
 * @return {number} a byte.
 */
DataReader.prototype.byteAt = function byteAt (i) {
    // see implementations
};

/**
 * Get the next number with a given byte size.
 * @param {number} size the number of bytes to read.
 * @return {number} the corresponding number.
 */
DataReader.prototype.readInt = function readInt (size) {
    var result = 0,
        i;
    this.checkOffset(size);
    for (i = this.index + size - 1; i >= this.index; i--) {
        result = (result << 8) + this.byteAt(i);
    }
    this.index += size;
    return result;
};

/**
 * Get the next string with a given byte size.
 * @param {number} size the number of bytes to read.
 * @return {string} the corresponding string.
 */
DataReader.prototype.readString = function readString (size) {
    return transformTo("string", this.readData(size));
};

/**
 * Get raw data without conversion, <size> bytes.
 * @param {number} size the number of bytes to read.
 * @return {Object} the raw data, implementation specific.
 */
DataReader.prototype.readData = function readData (size) {
    // see implementations
};

/**
 * Find the last occurrence of a zip signature (4 bytes).
 * @param {string} sig the signature to find.
 * @return {number} the index of the last occurrence, -1 if not found.
 */
DataReader.prototype.lastIndexOfSignature = function lastIndexOfSignature (sig) {
    // see implementations
};

/**
 * Read the signature (4 bytes) at the current position and compare it with sig.
 * @param {string} sig the expected signature
 * @return {boolean} true if the signature matches, false otherwise.
 */
DataReader.prototype.readAndCheckSignature = function readAndCheckSignature (sig) {
    // see implementations
};

/**
 * Get the next date.
 * @return {Date} the date.
 */
DataReader.prototype.readDate = function readDate () {
    var dostime = this.readInt(4);
    return new Date(Date.UTC(
    ((dostime >> 25) & 0x7f) + 1980, // year
    ((dostime >> 21) & 0x0f) - 1, // month
    (dostime >> 16) & 0x1f, // day
    (dostime >> 11) & 0x1f, // hour
    (dostime >> 5) & 0x3f, // minute
    (dostime & 0x1f) << 1)); // second
};

/* eslint-disable */

var ArrayReader = /*@__PURE__*/(function (DataReader) {
    function ArrayReader(data) {
        DataReader.call(this, data);
        for(var i = 0; i < this.data.length; i++) {
            data[i] = data[i] & 0xFF;
        }
    }

    if ( DataReader ) ArrayReader.__proto__ = DataReader;
    ArrayReader.prototype = Object.create( DataReader && DataReader.prototype );
    ArrayReader.prototype.constructor = ArrayReader;

    /**
     * @see DataReader.byteAt
     */
    ArrayReader.prototype.byteAt = function byteAt (i) {
        return this.data[this.zero + i];
    };

    /**
     * @see DataReader.lastIndexOfSignature
     */
    ArrayReader.prototype.lastIndexOfSignature = function lastIndexOfSignature (sig) {
        var sig0 = sig.charCodeAt(0),
            sig1 = sig.charCodeAt(1),
            sig2 = sig.charCodeAt(2),
            sig3 = sig.charCodeAt(3);
        for (var i = this.length - 4; i >= 0; --i) {
            if (this.data[i] === sig0 && this.data[i + 1] === sig1 && this.data[i + 2] === sig2 && this.data[i + 3] === sig3) {
                return i - this.zero;
            }
        }

        return -1;
    };

    /**
     * @see DataReader.readAndCheckSignature
     */
    ArrayReader.prototype.readAndCheckSignature = function readAndCheckSignature (sig) {
        var sig0 = sig.charCodeAt(0),
            sig1 = sig.charCodeAt(1),
            sig2 = sig.charCodeAt(2),
            sig3 = sig.charCodeAt(3),
            data = this.readData(4);
        return sig0 === data[0] && sig1 === data[1] && sig2 === data[2] && sig3 === data[3];
    };

    /**
     * @see DataReader.readData
     */
    ArrayReader.prototype.readData = function readData (size) {
        this.checkOffset(size);
        if(size === 0) {
            return [];
        }
        var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);
        this.index += size;
        return result;
    };

    return ArrayReader;
}(DataReader));

var StringReader = /*@__PURE__*/(function (DataReader) {
    function StringReader(data) {
        DataReader.call(this, data);
    }

    if ( DataReader ) StringReader.__proto__ = DataReader;
    StringReader.prototype = Object.create( DataReader && DataReader.prototype );
    StringReader.prototype.constructor = StringReader;

    /**
     * @see DataReader.byteAt
     */
    StringReader.prototype.byteAt = function byteAt (i) {
        return this.data.charCodeAt(this.zero + i);
    };

    /**
     * @see DataReader.lastIndexOfSignature
     */
    StringReader.prototype.lastIndexOfSignature = function lastIndexOfSignature (sig) {
        return this.data.lastIndexOf(sig) - this.zero;
    };

    /**
     * @see DataReader.readAndCheckSignature
     */
    StringReader.prototype.readAndCheckSignature = function readAndCheckSignature (sig) {
        var data = this.readData(4);
        return sig === data;
    };

    /**
     * @see DataReader.readData
     */
    StringReader.prototype.readData = function readData (size) {
        this.checkOffset(size);
        // this will work because the constructor applied the "& 0xff" mask.
        var result = this.data.slice(this.zero + this.index, this.zero + this.index + size);
        this.index += size;
        return result;
    };

    return StringReader;
}(DataReader));

/* eslint-disable */

var Uint8ArrayReader = /*@__PURE__*/(function (ArrayReader) {
    function Uint8ArrayReader(data) {
        ArrayReader.call(this, data);
    }

    if ( ArrayReader ) Uint8ArrayReader.__proto__ = ArrayReader;
    Uint8ArrayReader.prototype = Object.create( ArrayReader && ArrayReader.prototype );
    Uint8ArrayReader.prototype.constructor = Uint8ArrayReader;

    /**
     * @see DataReader.readData
     */
    Uint8ArrayReader.prototype.readData = function readData (size) {
        this.checkOffset(size);
        if(size === 0) {
            // in IE10, when using subarray(idx, idx), we get the array [0x00] instead of [].
            return new Uint8Array(0);
        }
        var result = this.data.subarray(this.zero + this.index, this.zero + this.index + size);
        this.index += size;
        return result;
    };

    return Uint8ArrayReader;
}(ArrayReader));

/**
 * Create a reader adapted to the data.
 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data to read.
 * @return {DataReader} the data reader.
 */
function readerFor(data) {
    var type = getTypeOf(data);
    checkSupport(type);
    if (type === "string" && !support.uint8array) {
        return new StringReader(data);
    }
    if (support.uint8array) {
        return new Uint8ArrayReader(transformTo("uint8array", data));
    }
    return new ArrayReader(transformTo("array", data));
}

/* eslint-disable */

var MADE_BY_DOS = 0x00;
var MADE_BY_UNIX = 0x03;

/**
 * Find a compression registered in JSZip.
 * @param {string} compressionMethod the method magic to find.
 * @return {Object|null} the JSZip compression object, null if none found.
 */
var findCompression = function(compressionMethod) {
    for (var method in compressions) {
        if (!compressions.hasOwnProperty(method)) {
            continue;
        }
        if (compressions[method].magic === compressionMethod) {
            return compressions[method];
        }
    }
    return null;
};

// class ZipEntry {{{
/**
 * An entry in the zip file.
 * @constructor
 * @param {Object} options Options of the current file.
 * @param {Object} loadOptions Options for loading the stream.
 */
var ZipEntry = function ZipEntry(options, loadOptions) {
    this.options = options;
    this.loadOptions = loadOptions;
};

/**
 * say if the file is encrypted.
 * @return {boolean} true if the file is encrypted, false otherwise.
 */
ZipEntry.prototype.isEncrypted = function isEncrypted () {
    // bit 1 is set
    return (this.bitFlag & 0x0001) === 0x0001;
};

/**
 * say if the file has utf-8 filename/comment.
 * @return {boolean} true if the filename/comment is in utf-8, false otherwise.
 */
ZipEntry.prototype.useUTF8 = function useUTF8 () {
    // bit 11 is set
    return (this.bitFlag & 0x0800) === 0x0800;
};

/**
 * Read the local part of a zip file and add the info in this object.
 * @param {DataReader} reader the reader to use.
 */
ZipEntry.prototype.readLocalPart = function readLocalPart (reader) {
    var compression, localExtraFieldsLength;

    // we already know everything from the central dir !
    // If the central dir data are false, we are doomed.
    // On the bright side, the local part is scary  : zip64, data descriptors, both, etc.
    // The less data we get here, the more reliable this should be.
    // Let's skip the whole header and dash to the data !
    reader.skip(22);
    // in some zip created on windows, the filename stored in the central dir contains \ instead of /.
    // Strangely, the filename here is OK.
    // I would love to treat these zip files as corrupted (see http://www.info-zip.org/FAQ.html#backslashes
    // or APPNOTE#4.4.17.1, "All slashes MUST be forward slashes '/'") but there are a lot of bad zip generators...
    // Search "unzip mismatching "local" filename continuing with "central" filename version" on
    // the internet.
    //
    // I think I see the logic here : the central directory is used to display
    // content and the local directory is used to extract the files. Mixing / and \
    // may be used to display \ to windows users and use / when extracting the files.
    // Unfortunately, this lead also to some issues : http://seclists.org/fulldisclosure/2009/Sep/394
    this.fileNameLength = reader.readInt(2);
    localExtraFieldsLength = reader.readInt(2); // can't be sure this will be the same as the central dir
    // the fileName is stored as binary data, the handleUTF8 method will take care of the encoding.
    this.fileName = reader.readData(this.fileNameLength);
    reader.skip(localExtraFieldsLength);

    if (this.compressedSize === -1 || this.uncompressedSize === -1) {
        throw new Error("Bug or corrupted zip : didn't get enough information from the central directory " + "(compressedSize === -1 || uncompressedSize === -1)");
    }

    compression = findCompression(this.compressionMethod);
    if (compression === null) { // no compression found
        throw new Error("Corrupted zip : compression " + pretty(this.compressionMethod) + " unknown (inner file : " + transformTo("string", this.fileName) + ")");
    }
    this.decompressed = new CompressedObject(this.compressedSize, this.uncompressedSize, this.crc32, compression, reader.readData(this.compressedSize));
};

/**
 * Read the central part of a zip file and add the info in this object.
 * @param {DataReader} reader the reader to use.
 */
ZipEntry.prototype.readCentralPart = function readCentralPart (reader) {
    this.versionMadeBy = reader.readInt(2);
    reader.skip(2);
    // this.versionNeeded = reader.readInt(2);
    this.bitFlag = reader.readInt(2);
    this.compressionMethod = reader.readString(2);
    this.date = reader.readDate();
    this.crc32 = reader.readInt(4);
    this.compressedSize = reader.readInt(4);
    this.uncompressedSize = reader.readInt(4);
    var fileNameLength = reader.readInt(2);
    this.extraFieldsLength = reader.readInt(2);
    this.fileCommentLength = reader.readInt(2);
    this.diskNumberStart = reader.readInt(2);
    this.internalFileAttributes = reader.readInt(2);
    this.externalFileAttributes = reader.readInt(4);
    this.localHeaderOffset = reader.readInt(4);

    if (this.isEncrypted()) {
        throw new Error("Encrypted zip are not supported");
    }

    // will be read in the local part, see the comments there
    reader.skip(fileNameLength);
    this.readExtraFields(reader);
    this.parseZIP64ExtraField(reader);
    this.fileComment = reader.readData(this.fileCommentLength);
};

/**
 * Parse the external file attributes and get the unix/dos permissions.
 */
ZipEntry.prototype.processAttributes = function processAttributes () {
    this.unixPermissions = null;
    this.dosPermissions = null;
    var madeBy = this.versionMadeBy >> 8;

    // Check if we have the DOS directory flag set.
    // We look for it in the DOS and UNIX permissions
    // but some unknown platform could set it as a compatibility flag.
    this.dir = this.externalFileAttributes & 0x0010 ? true : false;

    if(madeBy === MADE_BY_DOS) {
        // first 6 bits (0 to 5)
        this.dosPermissions = this.externalFileAttributes & 0x3F;
    }

    if(madeBy === MADE_BY_UNIX) {
        this.unixPermissions = (this.externalFileAttributes >> 16) & 0xFFFF;
        // the octal permissions are in (this.unixPermissions & 0x01FF).toString(8);
    }

    // fail safe : if the name ends with a / it probably means a folder
    if (!this.dir && this.fileNameStr.slice(-1) === '/') {
        this.dir = true;
    }
};

/**
 * Parse the ZIP64 extra field and merge the info in the current ZipEntry.
 * @param {DataReader} reader the reader to use.
 */
ZipEntry.prototype.parseZIP64ExtraField = function parseZIP64ExtraField (reader) {

    if (!this.extraFields[0x0001]) {
        return;
    }

    // should be something, preparing the extra reader
    var extraReader = readerFor(this.extraFields[0x0001].value);

    // I really hope that these 64bits integer can fit in 32 bits integer, because js
    // won't let us have more.
    if (this.uncompressedSize === MAX_VALUE_32BITS) {
        this.uncompressedSize = extraReader.readInt(8);
    }
    if (this.compressedSize === MAX_VALUE_32BITS) {
        this.compressedSize = extraReader.readInt(8);
    }
    if (this.localHeaderOffset === MAX_VALUE_32BITS) {
        this.localHeaderOffset = extraReader.readInt(8);
    }
    if (this.diskNumberStart === MAX_VALUE_32BITS) {
        this.diskNumberStart = extraReader.readInt(4);
    }
};

/**
 * Read the central part of a zip file and add the info in this object.
 * @param {DataReader} reader the reader to use.
 */
ZipEntry.prototype.readExtraFields = function readExtraFields (reader) {
    var end = reader.index + this.extraFieldsLength,
        extraFieldId,
        extraFieldLength,
        extraFieldValue;

    if (!this.extraFields) {
        this.extraFields = {};
    }

    while (reader.index < end) {
        extraFieldId = reader.readInt(2);
        extraFieldLength = reader.readInt(2);
        extraFieldValue = reader.readData(extraFieldLength);

        this.extraFields[extraFieldId] = {
            id: extraFieldId,
            length: extraFieldLength,
            value: extraFieldValue
        };
    }
};

/**
 * Apply an UTF8 transformation if needed.
 */
ZipEntry.prototype.handleUTF8 = function handleUTF8 () {
    var decodeParamType = support.uint8array ? "uint8array" : "array";
    if (this.useUTF8()) {
        this.fileNameStr = utf8decode(this.fileName);
        this.fileCommentStr = utf8decode(this.fileComment);
    } else {
        var upath = this.findExtraFieldUnicodePath();
        if (upath !== null) {
            this.fileNameStr = upath;
        } else {
            // ASCII text or unsupported code page
            var fileNameByteArray =  transformTo(decodeParamType, this.fileName);
            this.fileNameStr = this.loadOptions.decodeFileName(fileNameByteArray);
        }

        var ucomment = this.findExtraFieldUnicodeComment();
        if (ucomment !== null) {
            this.fileCommentStr = ucomment;
        } else {
            // ASCII text or unsupported code page
            var commentByteArray =  transformTo(decodeParamType, this.fileComment);
            this.fileCommentStr = this.loadOptions.decodeFileName(commentByteArray);
        }
    }
};

/**
 * Find the unicode path declared in the extra field, if any.
 * @return {String} the unicode path, null otherwise.
 */
ZipEntry.prototype.findExtraFieldUnicodePath = function findExtraFieldUnicodePath () {
    var upathField = this.extraFields[0x7075];
    if (upathField) {
        var extraReader = readerFor(upathField.value);

        // wrong version
        if (extraReader.readInt(1) !== 1) {
            return null;
        }

        // the crc of the filename changed, this field is out of date.
        if (crc32wrapper(this.fileName) !== extraReader.readInt(4)) {
            return null;
        }

        return utf8decode(extraReader.readData(upathField.length - 5));
    }
    return null;
};

/**
 * Find the unicode comment declared in the extra field, if any.
 * @return {String} the unicode comment, null otherwise.
 */
ZipEntry.prototype.findExtraFieldUnicodeComment = function findExtraFieldUnicodeComment () {
    var ucommentField = this.extraFields[0x6375];
    if (ucommentField) {
        var extraReader = readerFor(ucommentField.value);

        // wrong version
        if (extraReader.readInt(1) !== 1) {
            return null;
        }

        // the crc of the comment changed, this field is out of date.
        if (crc32wrapper(this.fileComment) !== extraReader.readInt(4)) {
            return null;
        }

        return utf8decode(extraReader.readData(ucommentField.length - 5));
    }
    return null;
};

/* eslint-disable */

//  class ZipEntries {{{
/**
 * All the entries in the zip file.
 * @constructor
 * @param {Object} loadOptions Options for loading the stream.
 */
var ZipEntries = function ZipEntries(loadOptions) {
    this.files = [];
    this.loadOptions = loadOptions;
};

/**
 * Check that the reader is on the specified signature.
 * @param {string} expectedSignature the expected signature.
 * @throws {Error} if it is an other signature.
 */
ZipEntries.prototype.checkSignature = function checkSignature (expectedSignature) {
    if (!this.reader.readAndCheckSignature(expectedSignature)) {
        this.reader.index -= 4;
        var signature = this.reader.readString(4);
        throw new Error("Corrupted zip or bug: unexpected signature " + "(" + pretty(signature) + ", expected " + pretty(expectedSignature) + ")");
    }
};

/**
 * Check if the given signature is at the given index.
 * @param {number} askedIndex the index to check.
 * @param {string} expectedSignature the signature to expect.
 * @return {boolean} true if the signature is here, false otherwise.
 */
ZipEntries.prototype.isSignature = function isSignature (askedIndex, expectedSignature) {
    var currentIndex = this.reader.index;
    this.reader.setIndex(askedIndex);
    var signature = this.reader.readString(4);
    var result = signature === expectedSignature;
    this.reader.setIndex(currentIndex);
    return result;
};

/**
 * Read the end of the central directory.
 */
ZipEntries.prototype.readBlockEndOfCentral = function readBlockEndOfCentral () {
    this.diskNumber = this.reader.readInt(2);
    this.diskWithCentralDirStart = this.reader.readInt(2);
    this.centralDirRecordsOnThisDisk = this.reader.readInt(2);
    this.centralDirRecords = this.reader.readInt(2);
    this.centralDirSize = this.reader.readInt(4);
    this.centralDirOffset = this.reader.readInt(4);

    this.zipCommentLength = this.reader.readInt(2);
    // warning : the encoding depends of the system locale
    // On a linux machine with LANG=en_US.utf8, this field is utf8 encoded.
    // On a windows machine, this field is encoded with the localized windows code page.
    var zipComment = this.reader.readData(this.zipCommentLength);
    var decodeParamType = support.uint8array ? "uint8array" : "array";
    // To get consistent behavior with the generation part, we will assume that
    // this is utf8 encoded unless specified otherwise.
    var decodeContent = transformTo(decodeParamType, zipComment);
    this.zipComment = this.loadOptions.decodeFileName(decodeContent);
};

/**
 * Read the end of the Zip 64 central directory.
 * Not merged with the method readEndOfCentral :
 * The end of central can coexist with its Zip64 brother,
 * I don't want to read the wrong number of bytes !
 */
ZipEntries.prototype.readBlockZip64EndOfCentral = function readBlockZip64EndOfCentral () {
    this.zip64EndOfCentralSize = this.reader.readInt(8);
    this.reader.skip(4);
    // this.versionMadeBy = this.reader.readString(2);
    // this.versionNeeded = this.reader.readInt(2);
    this.diskNumber = this.reader.readInt(4);
    this.diskWithCentralDirStart = this.reader.readInt(4);
    this.centralDirRecordsOnThisDisk = this.reader.readInt(8);
    this.centralDirRecords = this.reader.readInt(8);
    this.centralDirSize = this.reader.readInt(8);
    this.centralDirOffset = this.reader.readInt(8);

    this.zip64ExtensibleData = {};
    var extraDataSize = this.zip64EndOfCentralSize - 44,
        index = 0,
        extraFieldId,
        extraFieldLength,
        extraFieldValue;
    while (index < extraDataSize) {
        extraFieldId = this.reader.readInt(2);
        extraFieldLength = this.reader.readInt(4);
        extraFieldValue = this.reader.readData(extraFieldLength);
        this.zip64ExtensibleData[extraFieldId] = {
            id: extraFieldId,
            length: extraFieldLength,
            value: extraFieldValue
        };
    }
};

/**
 * Read the end of the Zip 64 central directory locator.
 */
ZipEntries.prototype.readBlockZip64EndOfCentralLocator = function readBlockZip64EndOfCentralLocator () {
    this.diskWithZip64CentralDirStart = this.reader.readInt(4);
    this.relativeOffsetEndOfZip64CentralDir = this.reader.readInt(8);
    this.disksCount = this.reader.readInt(4);
    if (this.disksCount > 1) {
        throw new Error("Multi-volumes zip are not supported");
    }
};

/**
 * Read the local files, based on the offset read in the central part.
 */
ZipEntries.prototype.readLocalFiles = function readLocalFiles () {
    var i, file;
    for (i = 0; i < this.files.length; i++) {
        file = this.files[i];
        this.reader.setIndex(file.localHeaderOffset);
        this.checkSignature(LOCAL_FILE_HEADER);
        file.readLocalPart(this.reader);
        file.handleUTF8();
        file.processAttributes();
    }
};

/**
 * Read the central directory.
 */
ZipEntries.prototype.readCentralDir = function readCentralDir () {
    var file;

    this.reader.setIndex(this.centralDirOffset);
    while (this.reader.readAndCheckSignature(CENTRAL_FILE_HEADER)) {
        file = new ZipEntry({
            zip64: this.zip64
        }, this.loadOptions);
        file.readCentralPart(this.reader);
        this.files.push(file);
    }

    if (this.centralDirRecords !== this.files.length) {
        if (this.centralDirRecords !== 0 && this.files.length === 0) {
            // We expected some records but couldn't find ANY.
            // This is really suspicious, as if something went wrong.
            throw new Error("Corrupted zip or bug: expected " + this.centralDirRecords + " records in central dir, got " + this.files.length);
        }
    }
};

/**
 * Read the end of central directory.
 */
ZipEntries.prototype.readEndOfCentral = function readEndOfCentral () {
    var offset = this.reader.lastIndexOfSignature(CENTRAL_DIRECTORY_END);
    if (offset < 0) {
        // Check if the content is a truncated zip or complete garbage.
        // A "LOCAL_FILE_HEADER" is not required at the beginning (auto
        // extractible zip for example) but it can give a good hint.
        // If an ajax request was used without responseType, we will also
        // get unreadable data.
        var isGarbage = !this.isSignature(0, LOCAL_FILE_HEADER);

        if (isGarbage) {
            throw new Error("Can't find end of central directory : is this a zip file ? " +
                            "If it is, see https://stuk.github.io/jszip/documentation/howto/read_zip.html");
        } else {
            throw new Error("Corrupted zip: can't find end of central directory");
        }

    }
    this.reader.setIndex(offset);
    var endOfCentralDirOffset = offset;
    this.checkSignature(CENTRAL_DIRECTORY_END);
    this.readBlockEndOfCentral();


    /* extract from the zip spec :
        4)  If one of the fields in the end of central directory
            record is too small to hold required data, the field
            should be set to -1 (0xFFFF or 0xFFFFFFFF) and the
            ZIP64 format record should be created.
        5)  The end of central directory record and the
            Zip64 end of central directory locator record must
            reside on the same disk when splitting or spanning
            an archive.
     */
    if (this.diskNumber === MAX_VALUE_16BITS || this.diskWithCentralDirStart === MAX_VALUE_16BITS || this.centralDirRecordsOnThisDisk === MAX_VALUE_16BITS || this.centralDirRecords === MAX_VALUE_16BITS || this.centralDirSize === MAX_VALUE_32BITS || this.centralDirOffset === MAX_VALUE_32BITS) {
        this.zip64 = true;

        /*
        Warning : the zip64 extension is supported, but ONLY if the 64bits integer read from
        the zip file can fit into a 32bits integer. This cannot be solved : JavaScript represents
        all numbers as 64-bit double precision IEEE 754 floating point numbers.
        So, we have 53bits for integers and bitwise operations treat everything as 32bits.
        see https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Operators/Bitwise_Operators
        and http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-262.pdf section 8.5
        */

        // should look for a zip64 EOCD locator
        offset = this.reader.lastIndexOfSignature(ZIP64_CENTRAL_DIRECTORY_LOCATOR);
        if (offset < 0) {
            throw new Error("Corrupted zip: can't find the ZIP64 end of central directory locator");
        }
        this.reader.setIndex(offset);
        this.checkSignature(ZIP64_CENTRAL_DIRECTORY_LOCATOR);
        this.readBlockZip64EndOfCentralLocator();

        // now the zip64 EOCD record
        if (!this.isSignature(this.relativeOffsetEndOfZip64CentralDir, ZIP64_CENTRAL_DIRECTORY_END)) {
            // console.warn("ZIP64 end of central directory not where expected.");
            this.relativeOffsetEndOfZip64CentralDir = this.reader.lastIndexOfSignature(ZIP64_CENTRAL_DIRECTORY_END);
            if (this.relativeOffsetEndOfZip64CentralDir < 0) {
                throw new Error("Corrupted zip: can't find the ZIP64 end of central directory");
            }
        }
        this.reader.setIndex(this.relativeOffsetEndOfZip64CentralDir);
        this.checkSignature(ZIP64_CENTRAL_DIRECTORY_END);
        this.readBlockZip64EndOfCentral();
    }

    var expectedEndOfCentralDirOffset = this.centralDirOffset + this.centralDirSize;
    if (this.zip64) {
        expectedEndOfCentralDirOffset += 20; // end of central dir 64 locator
        expectedEndOfCentralDirOffset += 12 /* should not include the leading 12 bytes */ + this.zip64EndOfCentralSize;
    }

    var extraBytes = endOfCentralDirOffset - expectedEndOfCentralDirOffset;

    if (extraBytes > 0) {
        // console.warn(extraBytes, "extra bytes at beginning or within zipfile");
        if (this.isSignature(endOfCentralDirOffset, CENTRAL_FILE_HEADER)) ; else {
            // the offset is wrong, update the "zero" of the reader
            // this happens if data has been prepended (crx files for example)
            this.reader.zero = extraBytes;
        }
    } else if (extraBytes < 0) {
        throw new Error("Corrupted zip: missing " + Math.abs(extraBytes) + " bytes.");
    }
};

ZipEntries.prototype.prepareReader = function prepareReader (data) {
    this.reader = readerFor(data);
};

/**
 * Read a zip file and create ZipEntries.
 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the binary string representing a zip file.
 */
ZipEntries.prototype.load = function load (data) {
    this.prepareReader(data);
    this.readEndOfCentral();
    this.readCentralDir();
    this.readLocalFiles();
};

/* eslint-disable */

/**
 * Check the CRC32 of an entry.
 * @param {ZipEntry} zipEntry the zip entry to check.
 * @return {Promise} the result.
 */
function checkEntryCRC32(zipEntry) {
    return new external.Promise(function (resolve, reject) {
        var worker = zipEntry.decompressed.getContentWorker().pipe(new Crc32Probe());
        worker.on("error", function (e) {
            reject(e);
        })
        .on("end", function () {
            if (worker.streamInfo.crc32 !== zipEntry.decompressed.crc32) {
                reject(new Error("Corrupted zip : CRC32 mismatch"));
            } else {
                resolve();
            }
        })
        .resume();
    });
}

function load(data, options) {
    var zip = this;
    options = extend(options || {}, {
        base64: false,
        checkCRC32: false,
        optimizedBinaryString: false,
        createFolders: false,
        decodeFileName: utf8decode
    });

    return prepareContent("the loaded zip file", data, true, options.optimizedBinaryString, options.base64)
    .then(function(data) {
        var zipEntries = new ZipEntries(options);
        zipEntries.load(data);
        return zipEntries;
    }).then(function checkCRC32(zipEntries) {
        var promises = [external.Promise.resolve(zipEntries)];
        var files = zipEntries.files;
        if (options.checkCRC32) {
            for (var i = 0; i < files.length; i++) {
                promises.push(checkEntryCRC32(files[i]));
            }
        }
        return external.Promise.all(promises);
    }).then(function addFiles(results) {
        var zipEntries = results.shift();
        var files = zipEntries.files;
        for (var i = 0; i < files.length; i++) {
            var input = files[i];
            zip.file(input.fileNameStr, input.decompressed, {
                binary: true,
                optimizedBinaryString: true,
                date: input.date,
                dir: input.dir,
                comment : input.fileCommentStr.length ? input.fileCommentStr : null,
                unixPermissions : input.unixPermissions,
                dosPermissions : input.dosPermissions,
                createFolders: options.createFolders
            });
        }
        if (zipEntries.zipComment.length) {
            zip.comment = zipEntries.zipComment;
        }

        return zip;
    });
}

/* eslint-disable */

/**
 * Add a file in the current folder.
 * @private
 * @param {string} name the name of the file
 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data of the file
 * @param {Object} originalOptions the options of the file
 * @return {Object} the new file.
 */
var fileAdd = function(name, data, originalOptions) {
    // be sure sub folders exist
    var dataType = getTypeOf(data),
        parent;


    /*
     * Correct options.
     */

    var o = extend(originalOptions || {}, defaults);
    o.date = o.date || new Date();
    if (o.compression !== null) {
        o.compression = o.compression.toUpperCase();
    }

    if (typeof o.unixPermissions === "string") {
        o.unixPermissions = parseInt(o.unixPermissions, 8);
    }

    // UNX_IFDIR  0040000 see zipinfo.c
    if (o.unixPermissions && (o.unixPermissions & 0x4000)) {
        o.dir = true;
    }
    // Bit 4    Directory
    if (o.dosPermissions && (o.dosPermissions & 0x0010)) {
        o.dir = true;
    }

    if (o.dir) {
        name = forceTrailingSlash(name);
    }
    if (o.createFolders && (parent = parentFolder(name))) {
        folderAdd.call(this, parent, true);
    }

    var isUnicodeString = dataType === "string" && o.binary === false && o.base64 === false;
    if (!originalOptions || typeof originalOptions.binary === "undefined") {
        o.binary = !isUnicodeString;
    }


    var isCompressedEmpty = (data instanceof CompressedObject) && data.uncompressedSize === 0;

    if (isCompressedEmpty || o.dir || !data || data.length === 0) {
        o.base64 = false;
        o.binary = true;
        data = "";
        o.compression = "STORE";
        dataType = "string";
    }

    /*
     * Convert content to fit.
     */

    var zipObjectContent = null;
    if (data instanceof CompressedObject || data instanceof GenericWorker) {
        zipObjectContent = data;
    } else {
        zipObjectContent = prepareContent(name, data, o.binary, o.optimizedBinaryString, o.base64);
    }

    var object = new ZipObject(name, zipObjectContent, o);
    this.files[name] = object;
    /*
    TODO: we can't throw an exception because we have async promises
    (we can have a promise of a Date() for example) but returning a
    promise is useless because file(name, data) returns the JSZip
    object for chaining. Should we break that to allow the user
    to catch the error ?

    return external.Promise.resolve(zipObjectContent)
    .then(function () {
        return object;
    });
    */
};

/**
 * Find the parent folder of the path.
 * @private
 * @param {string} path the path to use
 * @return {string} the parent folder, or ""
 */
var parentFolder = function (path) {
    if (path.slice(-1) === '/') {
        path = path.substring(0, path.length - 1);
    }
    var lastSlash = path.lastIndexOf('/');
    return (lastSlash > 0) ? path.substring(0, lastSlash) : "";
};

/**
 * Returns the path with a slash at the end.
 * @private
 * @param {String} path the path to check.
 * @return {String} the path with a trailing slash.
 */
var forceTrailingSlash = function(path) {
    // Check the name ends with a /
    if (path.slice(-1) !== "/") {
        path += "/"; // IE doesn't like substr(-1)
    }
    return path;
};

/**
 * Add a (sub) folder in the current folder.
 * @private
 * @param {string} name the folder's name
 * @param {boolean=} [createFolders] If true, automatically create sub
 *  folders. Defaults to false.
 * @return {Object} the new folder.
 */
var folderAdd = function(name, createFolders$1) {
    createFolders$1 = (typeof createFolders$1 !== 'undefined') ? createFolders$1 : createFolders;

    name = forceTrailingSlash(name);

    // Does this folder already exist?
    if (!this.files[name]) {
        fileAdd.call(this, name, null, {
            dir: true,
            createFolders: createFolders$1
        });
    }
    return this.files[name];
};

/**
* Cross-window, cross-Node-context regular expression detection
* @param  {Object}  object Anything
* @return {Boolean}        true if the object is a regular expression,
* false otherwise
*/
function isRegExp(object) {
    return Object.prototype.toString.call(object) === "[object RegExp]";
}

/**
 * Representation a of zip file in js
 * @constructor
 */
var JSZip = function JSZip() {
    if (arguments.length) {
        throw new Error("The constructor with parameters has been removed in JSZip 3.0, please check the upgrade guide.");
    }

    // object containing the files :
    // {
    //   "folder/" : {...},
    //   "folder/data.txt" : {...}
    // }
    // NOTE: we use a null prototype because we do not
    // want filenames like "toString" coming from a zip file
    // to overwrite methods and attributes in a normal Object.
    this.files = Object.create(null);

    this.comment = null;

    // Where we are in the hierarchy
    this.root = "";
    this.clone = function() {
        var newObj = new JSZip();
        for (var i in this) {
            if (typeof this[i] !== "function") {
                newObj[i] = this[i];
            }
        }
        return newObj;
    };
};

var staticAccessors = { support: { configurable: true },defaults: { configurable: true },version: { configurable: true },external: { configurable: true } };

/**
 * @see loadAsync
 */
JSZip.prototype.load = function load () {
    throw new Error("This method has been removed in JSZip 3.0, please check the upgrade guide.");
};

/**
 * Call a callback function for each entry at this folder level.
 * @param {Function} cb the callback function:
 * function (relativePath, file) {...}
 * It takes 2 arguments : the relative path and the file.
 */
JSZip.prototype.forEach = function forEach (cb) {
    var filename, relativePath, file;
    for (filename in this.files) {
        file = this.files[filename];
        relativePath = filename.slice(this.root.length, filename.length);
        if (relativePath && filename.slice(0, this.root.length) === this.root) { // the file is in the current root
            cb(relativePath, file); // TODO reverse the parameters ? need to be clean AND consistent with the filter search fn...
        }
    }
};

/**
 * Filter nested files/folders with the specified function.
 * @param {Function} search the predicate to use :
 * function (relativePath, file) {...}
 * It takes 2 arguments : the relative path and the file.
 * @return {Array} An array of matching elements.
 */
JSZip.prototype.filter = function filter (search) {
    var result = [];
    this.forEach(function (relativePath, entry) {
        if (search(relativePath, entry)) { // the file matches the function
            result.push(entry);
        }

    });
    return result;
};

/**
 * Add a file to the zip file, or search a file.
 * @param   {string|RegExp} name The name of the file to add (if data is defined),
 * the name of the file to find (if no data) or a regex to match files.
 * @param   {String|ArrayBuffer|Uint8Array|Buffer} data  The file data, either raw or base64 encoded
 * @param   {Object} o File options
 * @return  {JSZip|Object|Array} this JSZip object (when adding a file),
 * a file (when searching by string) or an array of files (when searching by regex).
 */
JSZip.prototype.file = function file (name, data, o) {
    if (arguments.length === 1) {
        if (isRegExp(name)) {
            var regexp = name;
            return this.filter(function(relativePath, file) {
                return !file.dir && regexp.test(relativePath);
            });
        }
        else { // text
            var obj = this.files[this.root + name];
            if (obj && !obj.dir) {
                return obj;
            } else {
                return null;
            }
        }
    }
    else { // more than one argument : we have data !
        name = this.root + name;
        fileAdd.call(this, name, data, o);
    }
    return this;
};

/**
 * Add a directory to the zip file, or search.
 * @param   {String|RegExp} arg The name of the directory to add, or a regex to search folders.
 * @return  {JSZip} an object with the new directory as the root, or an array containing matching folders.
 */
JSZip.prototype.folder = function folder (arg) {
    if (!arg) {
        return this;
    }

    if (isRegExp(arg)) {
        return this.filter(function(relativePath, file) {
            return file.dir && arg.test(relativePath);
        });
    }

    // else, name is a new folder
    var name = this.root + arg;
    var newFolder = folderAdd.call(this, name);

    // Allow chaining by returning a new object with this folder as the root
    var ret = this.clone();
    ret.root = newFolder.name;
    return ret;
};

/**
 * Delete a file, or a directory and all sub-files, from the zip
 * @param {string} name the name of the file to delete
 * @return {JSZip} this JSZip object
 */
JSZip.prototype.remove = function remove (name) {
    name = this.root + name;
    var file = this.files[name];
    if (!file) {
        // Look for any folders
        if (name.slice(-1) !== "/") {
            name += "/";
        }
        file = this.files[name];
    }

    if (file && !file.dir) {
        // file
        delete this.files[name];
    } else {
        // maybe a folder, delete recursively
        var kids = this.filter(function(relativePath, file) {
            return file.name.slice(0, name.length) === name;
        });
        for (var i = 0; i < kids.length; i++) {
            delete this.files[kids[i].name];
        }
    }

    return this;
};

/**
 * Generate the complete zip file
 * @param {Object} options the options to generate the zip file :
 * - compression, "STORE" by default.
 * - type, "base64" by default. Values are : string, base64, uint8array, arraybuffer, blob.
 * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the zip file
 */
JSZip.prototype.generate = function generate (options) {
    throw new Error("This method has been removed in JSZip 3.0, please check the upgrade guide.");
};

/**
 * Generate the complete zip file as an internal stream.
 * @param {Object} options the options to generate the zip file :
 * - compression, "STORE" by default.
 * - type, "base64" by default. Values are : string, base64, uint8array, arraybuffer, blob.
 * @return {StreamHelper} the streamed zip file.
 */
JSZip.prototype.generateInternalStream = function generateInternalStream (options) {
  var worker, opts = {};
  try {
      opts = extend(options || {}, {
          streamFiles: false,
          compression: "STORE",
          compressionOptions : null,
          type: "",
          platform: "DOS",
          comment: null,
          mimeType: 'application/zip',
          encodeFileName: utf8encode
      });

      opts.type = opts.type.toLowerCase();
      opts.compression = opts.compression.toUpperCase();

      // "binarystring" is preferred but the internals use "string".
      if(opts.type === "binarystring") {
        opts.type = "string";
      }

      if (!opts.type) {
        throw new Error("No output type specified.");
      }

      checkSupport(opts.type);

      // accept nodejs `process.platform`
      if(
          opts.platform === 'darwin' ||
          opts.platform === 'freebsd' ||
          opts.platform === 'linux' ||
          opts.platform === 'sunos'
      ) {
          opts.platform = "UNIX";
      }
      if (opts.platform === 'win32') {
          opts.platform = "DOS";
      }

      var comment = opts.comment || this.comment || "";
      worker = generateWorker(this, opts, comment);
  } catch (e) {
    worker = new GenericWorker("error");
    worker.error(e);
  }
  return new StreamHelper(worker, opts.type || "string", opts.mimeType);
};

/**
 * Generate the complete zip file asynchronously.
 * @see generateInternalStream
 */
JSZip.prototype.generateAsync = function generateAsync (options, onUpdate) {
    return this.generateInternalStream(options).accumulate(onUpdate);
};

JSZip.prototype.loadAsync = function loadAsync (data, options) {
    return load.apply(this, [data, options]);
};

JSZip.loadAsync = function loadAsync (content, options) {
    return new JSZip().loadAsync(content, options);
};
    
staticAccessors.support.get = function () {
    return support;
};

staticAccessors.defaults.get = function () {
    return defaults;
};

staticAccessors.version.get = function () {
    return "3.2.2-esm";
};

staticAccessors.external.get = function () {
    return external;
};

Object.defineProperties( JSZip, staticAccessors );

export { JSZip as default };
